{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data associated with bills: utterances, summaries; so they are ready for input to pointer-gen model - this is the new cleaning method implementation\n",
    "\n",
    "There are 6541 BIDs which overlap between the utterances and summaries datasets (using all the summary data). There are 359 instances in which the summaries are greater than 100 tokens in length, and 41 instances in which the summaries are greater than 201 tokens in length. In these instances, the summaries with less than 201 tokens were cut to their first 100 tokens (anything over 201 tokens is cut entirely). There are 374 instances in which the utterances are less than 70 tokens in length. In the final dataset(old) of 6000 examples, there are 865 examples of resolutions.\n",
    "\n",
    "There are 374+127=501 instances in which the utterances are less than 100 tokens in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter,defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bill_summaries.json\") as summaries_file: # loading in the data\n",
    "    bill_summaries = json.load(summaries_file)\n",
    "    \n",
    "with open(\"../data/bill_utterances.json\") as utterances_file:\n",
    "    bill_utterances = json.load(utterances_file)\n",
    "    \n",
    "ca_bill_utterances = bill_utterances['CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data before the processing to format which is accepted by pointer-gen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bill_summaries(bill_summaries,max_summary_length=201,ignore_resolutions=False):\n",
    "    \"\"\" post-processing to remove bill summary entries with certain critera:\n",
    "          1) if the summary does not start with \"This\" (probable encoding error)\n",
    "          2) if \"page 1\" occurs in the text (indicates improper encoding)\n",
    "          3) if the text is over max_summary_length tokens in length (very long summaries indicate probable encoding error)\n",
    "        -for bill summaries which have ordering (\" 1)\",\" 2)\",\"(1)\",\"(2)\",\" a)\",\"(a)\"), removes the implicit ordering \n",
    "    \n",
    "    args:\n",
    "        summary_cutoff: the length of the summary for the text in which to keep\n",
    "        max_summary_length: max length of summaries in which to keep\n",
    "        ignore_resolutions (bool): whether to ignore resolutions and only output bills\n",
    "    \"\"\"\n",
    "    num_cutoff_counter=0 # counts the number of summaries ignored due to being too long\n",
    "    bill_summary_info = defaultdict(dict) # stores both summaries and utterances for each CA bill\n",
    "    for bid,summary in bill_summaries.items():\n",
    "        text = summary['text']\n",
    "        \n",
    "        if \"page 1\" in text: # ignore this instance, indicator of encoding error\n",
    "            continue\n",
    "        if text[0:4] != \"This\": # relatively strong indicator that there was error in encoding\n",
    "            continue\n",
    "        if ignore_resolutions and \"R\" in bid: # ignore this instance if wanting to ignore resolutions\n",
    "            continue\n",
    "            \n",
    "        tokens = [str(token) for token in nlp(text)] \n",
    "        if len(tokens)>max_summary_length: # ignore this instance, includes many errors in pdf encoding in which end state not reached\n",
    "            num_cutoff_counter += 1\n",
    "            continue\n",
    "        # removing the implicit ordering for all instances\n",
    "        if \" 1)\" in text or \" 2)\" in text or \"(1)\" in text or \"(2)\" in text or \" a)\" in text or \" b)\" in text or \"(a)\" in text or \"(b)\" in text:\n",
    "            text = re.sub(\" \\([0-9]\\)\",\"\",text)\n",
    "            text = re.sub(\" [0-9]\\)\",\"\",text)\n",
    "            text = re.sub(\" \\([a-j]\\)\",\"\",text)\n",
    "            text = re.sub(\" [a-j]\\)\",\"\",text)\n",
    "            tokens = [str(token) for token in nlp(text)]\n",
    "        \n",
    "        bill_summary_info[bid]['summary'] = summary\n",
    "        bill_summary_info[bid]['summary']['text']=text # text is occasionally updated (when ordering removed)\n",
    "        bill_summary_info[bid]['summary_tokens'] = tokens\n",
    "\n",
    "    return bill_summary_info,num_cutoff_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6897"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bill_summary_info,_ = clean_bill_summaries(bill_summaries,max_summary_length=650,ignore_resolutions=False)\n",
    "len(bill_summary_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bill_utterances(bill_summary_info,ca_bill_utterances,minimum_utterance_tokens=99,token_cutoff=1000,max_utterances=50):\n",
    "    \"\"\" cleans and combines the summary and utterance data\n",
    "        -also captures info about the hierarchical structure of utterances\n",
    "    args:\n",
    "        bill_summary_info: holds cleaned information about bill summaries\n",
    "        token_cutoff: max number of tokens to consider for utterances\n",
    "        minimum_utterance_tokens: minimum number of utterance tokens allowable\n",
    "        max_utterances: maximum number of of individual utterances\n",
    "    \"\"\"\n",
    "    num_utterance_counter=0 # counts num. examples ignored due to utterances being too short\n",
    "    all_bill_info = {}\n",
    "    all_tokens_dict = {} # stores all tokens for a given bid (ignoring token_cutoff)\n",
    "    \n",
    "    for bid in ca_bill_utterances:\n",
    "        if bid in bill_summary_info: # there is a summary assigned to this bill\n",
    "\n",
    "            all_utterances = [] # combining all discussions (did) for this bid together\n",
    "            for utterance_list in ca_bill_utterances[bid]['utterances']:\n",
    "                all_utterances+=utterance_list\n",
    "            \n",
    "            all_token_lists = [[str(token) for token in nlp(utterance)] for utterance in all_utterances]\n",
    "            utterance_lengths = [] # tracks number of tokens in each utterance\n",
    "            utterance_indices = [] # tracks index of last word in each utterance\n",
    "\n",
    "            all_tokens = [] # getting a single stream of tokens\n",
    "            cumulative_token_count=0 # used to track index of current last word in utterance\n",
    "            for token_list in all_token_lists:\n",
    "                if cumulative_token_count < token_cutoff: # ensures only utterances up to token_cutoff are considered\n",
    "                    utterance_lengths.append(min(len(token_list),token_cutoff-cumulative_token_count))\n",
    "                    utterance_indices.append(min(cumulative_token_count+len(token_list)-1,token_cutoff-1))\n",
    "                    cumulative_token_count += len(token_list)\n",
    "                all_tokens += token_list\n",
    "            \n",
    "            utterance_padding_num = max_utterances-len(utterance_lengths)\n",
    "            utterance_att_mask = [0 for _ in range(len(utterance_lengths))]+[-np.inf for _ in range(utterance_padding_num)]\n",
    "            utterance_lengths += [0 for _ in range(utterance_padding_num)]\n",
    "            utterance_indices += [0 for _ in range(utterance_padding_num)]\n",
    "            if cumulative_token_count < token_cutoff: # required padding if num. tokens is < token_cutoff\n",
    "                utterance_lengths[-1]=token_cutoff-cumulative_token_count\n",
    "                \n",
    "            if len(all_tokens)-len(all_token_lists)>=minimum_utterance_tokens: # ignore bids which don't have enough utterance tokens\n",
    "                all_tokens_dict[bid]=[token.lower() for token in all_tokens] # adding all utterance tokens\n",
    "                all_tokens_dict[bid]+=[token.lower() for token in bill_summary_info[bid]['summary_tokens']] # adding all summary tokens\n",
    "                all_bill_info[bid] = bill_summary_info[bid]\n",
    "                all_tokens = all_tokens[:token_cutoff] # taking up to max number of tokens\n",
    "                all_bill_info[bid]['utterance_att_mask']=utterance_att_mask # hierarchical input information\n",
    "                all_bill_info[bid]['utterance_indices']=utterance_indices\n",
    "                all_bill_info[bid]['utterance_lengths']=utterance_lengths\n",
    "                all_bill_info[bid]['utterances']=all_utterances # standard input information\n",
    "                all_bill_info[bid]['utterance_tokens']=all_tokens\n",
    "                all_bill_info[bid]['resolution'] = \"R\" in bid\n",
    "            else:\n",
    "                num_utterance_counter += 1\n",
    "\n",
    "    return all_bill_info,all_tokens_dict,num_utterance_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5900"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bill_info,all_tokens_dict,_ = clean_bill_utterances(bill_summary_info,ca_bill_utterances,token_cutoff=500)\n",
    "len(all_bill_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data to get to format which is accepted by pointer-gen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "### using pretrained Glove vectors\n",
    "word_to_embedding = {}\n",
    "with open(\"../data/glove.6B/glove.6B.100d.txt\") as glove_file:\n",
    "    for line in glove_file.readlines():\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:],dtype='float32')\n",
    "        word_to_embedding[word] = coefs\n",
    "print(len(word_to_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', ',', 'the', 'to', 'and', 'of', 'that', 'a', 'in', 'i']\n",
      "['ab1', '00', 'explication', 'fpcc', 'abrasively', 'mariella', 'shantz', 'hemmings', 'segerblom', 'utla']\n",
      "29997 17417\n"
     ]
    }
   ],
   "source": [
    "# getting all unique tokens used to get words which will be part of the fixed vocabulary\n",
    "## specifically specifying that I want a vocabulary size of 30k (adding less common words up to that threshold)\n",
    "all_tokens = []\n",
    "for bid in all_tokens_dict:\n",
    "    all_tokens += all_tokens_dict[bid]\n",
    "\n",
    "word_freq = Counter(all_tokens)\n",
    "words_by_freq = (list(word_freq.items()))\n",
    "words_by_freq.sort(key=lambda tup: tup[1],reverse=True) # sorting by occurance freq.\n",
    "\n",
    "most_freq_words = [word_tup[0] for word_tup in words_by_freq if word_tup[1] >= 3]\n",
    "most_freq_words += [word_tup[0] for word_tup in words_by_freq if word_tup[1] == 2 and word_tup[0] in word_to_embedding][:30000-3-len(most_freq_words)]\n",
    "less_freq_words = [word_tup[0] for word_tup in words_by_freq if word_tup[1] < 2]\n",
    "print(most_freq_words[0:10])\n",
    "print(less_freq_words[0:10])\n",
    "print(len(most_freq_words),len(less_freq_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 (30000, 100)\n"
     ]
    }
   ],
   "source": [
    "## new addition to this where I store the word embeddings for the vocabulary\n",
    "# assigning indices for all words, and adding <PAD>,<SENT>,<UNK> symbols\n",
    "fixed_vocab_word_to_index = {\"<PAD>\":0,\"<SENT>\":1,\"<UNK>\":2} # for words assigned to the fixed_vocabulary\n",
    "fixed_vocab_index_to_word = {0:\"<PAD>\",1:\"<SENT>\",2:\"<UNK>\"}\n",
    "\n",
    "word_embeddings = [np.random.uniform(low=-0.05,high=0.05,size=100).astype(\"float32\") for _ in range(3)]\n",
    "\n",
    "index = 3 # starting index for all words\n",
    "# assigning indices to most common words:\n",
    "for word in most_freq_words:\n",
    "    fixed_vocab_word_to_index[word]=index\n",
    "    fixed_vocab_index_to_word[index]=word\n",
    "    index += 1\n",
    "    if word in word_to_embedding: # use pre-trained embedding\n",
    "        word_embeddings.append(word_to_embedding[word])\n",
    "    else: # initialize a trainable embedding\n",
    "        word_embeddings.append(np.random.uniform(low=-0.05,high=0.05,size=100).astype(\"float32\"))\n",
    "\n",
    "word_embeddings = np.stack(word_embeddings)        \n",
    "print(len(fixed_vocab_word_to_index),word_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving all of the vocabulary related information\n",
    "np.save(\"../data/len_500_data/word_embeddings.npy\",word_embeddings)\n",
    "\n",
    "with open(\"../data/len_500_data/word_to_index.json\",\"w+\") as out_file:\n",
    "    json.dump(fixed_vocab_word_to_index,out_file)\n",
    "    \n",
    "with open(\"../data/len_500_data/index_to_word.json\",\"w+\") as out_file:\n",
    "    json.dump(fixed_vocab_index_to_word,out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fixed_words = len(fixed_vocab_word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cutoff=500 # this is the amount to pad up to for the input representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the input data representations for the model - input is padded up to a length of 500\n",
    "x = [] # stores the integer/index representation for all input\n",
    "x_indices = [] # stores the joint probability vector indices for all words in the input \n",
    "x_indices_dicts = [] # stores the dicts for assigning words which are not in the fixed_vocabulary\n",
    "att_mask = [] # stores the attention masks (0 for valid words, -np.inf for padding)\n",
    "utterance_att_masks = [] # hierarchical information\n",
    "utterance_indices = []\n",
    "utterance_lengths = []\n",
    "\n",
    "## data stores for debugging/error analysis\n",
    "bill_information_dict = {} # stores summary(text),utterances(2d list of utterances),resolution(boolean) for each BID\n",
    "bids = [] # stores the BIDs in sequential order\n",
    "\n",
    "for bid in all_bill_info:\n",
    "    # creating representations for data store\n",
    "    bill_information_dict[bid] = {\"summary\":all_bill_info[bid][\"summary\"][\"text\"],\"utterances\":all_bill_info[bid][\"utterances\"],\"resolution\":all_bill_info[bid][\"resolution\"]}\n",
    "    bids.append(bid)\n",
    "    \n",
    "    # saving hierarchical information:\n",
    "    utterance_att_masks.append(all_bill_info[bid]['utterance_att_mask'])\n",
    "    utterance_indices.append(all_bill_info[bid]['utterance_indices'])\n",
    "    utterance_lengths.append(all_bill_info[bid]['utterance_lengths'])\n",
    "    \n",
    "    # creating the standard input representation:\n",
    "    utterance_tokens = [token.lower() for token in all_bill_info[bid][\"utterance_tokens\"]]\n",
    "    \n",
    "    x_rep = [] # assigning indices to words, if input word not part of fixed_vocab, assign to <UNK>\n",
    "    for token in utterance_tokens:\n",
    "        if token in fixed_vocab_word_to_index:\n",
    "            x_rep.append(fixed_vocab_word_to_index[token])\n",
    "        else:\n",
    "            x_rep.append(fixed_vocab_word_to_index['<UNK>'])\n",
    "\n",
    "    att_mask_rep = [0 for i in range(len(x_rep))]\n",
    "    amount_to_pad = token_cutoff-len(x_rep)\n",
    "    x_rep += [0 for i in range(amount_to_pad)] # padding the input\n",
    "    att_mask_rep += [-np.inf for i in range(amount_to_pad)]\n",
    "    x.append(x_rep)\n",
    "    att_mask.append(att_mask_rep)\n",
    "    \n",
    "    # creating the joint probability representation for the input:\n",
    "    ## (the index in joint prob vector that each input word probability should be assigned to)\n",
    "    index=num_fixed_words # start index for assignment to joint_probability vector, length of fixed_vocab_size\n",
    "    non_vocab_dict = {} # stores all OOV words for this bid\n",
    "    this_x_indices = [] # joint prob vector indices for this bid\n",
    "    for token in utterance_tokens:\n",
    "        if token in fixed_vocab_word_to_index:\n",
    "            this_x_indices.append(fixed_vocab_word_to_index[token])\n",
    "        else:\n",
    "            if token in non_vocab_dict: # this word is OOV but has been seen before\n",
    "                this_x_indices.append(non_vocab_dict[token])\n",
    "            else: # this word is OOV and has never been seen before\n",
    "                non_vocab_dict[token]=index\n",
    "                this_x_indices.append(index)\n",
    "                index += 1\n",
    "    x_indices_dicts.append(non_vocab_dict)\n",
    "    this_x_indices += [0 for i in range(amount_to_pad)] # padding will be masked out in att calculation, so padding with 0 here is valid\n",
    "    x_indices.append(this_x_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the largest number of OOV words for a given bid utterances\n",
    "max([len(dic) for dic in x_indices_dicts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the output representations for the model - output is padded up to a length of 101\n",
    "## the last index is for <SENT> to indicate the end of decoding (assuming representation is shorter than 100 tokens)\n",
    "## assuming the summary is greater than 100 tokens in length, we simply cut off the first 101 tokens\n",
    "### when we do this cutoff, we do NOT include that <SENT> token as the 102nd token\n",
    "## all words in output that are not in input utterances or in fixed_vocab_vector are assigned 3:<UNK>\n",
    "y = [] # stores the index representations for all words in the headlines (this is never used)\n",
    "loss_mask = [] # 1 for valid words, 0 for padding\n",
    "decoder_x = [] # starts with 1:<SENT>, followed by y[0:len(headline)-1] (this is the input for teacher-forcing)(101x1)\n",
    "y_indices = [] # index for the correct decoder prediction, in the joint-probability vector\n",
    "\n",
    "total_oov_words = 0\n",
    "resolution_bools = [] # bool, whether a given example is a resolution (False=bill); used for train_test_split\n",
    "\n",
    "for bid_i,bid in enumerate(all_bill_info.keys()):\n",
    "    # creating standard output representation:\n",
    "    summary_tokens = [token.lower() for token in all_bill_info[bid][\"summary_tokens\"]]\n",
    "    \n",
    "    y_rep = [] # not used in the model, stores indices using only fixed_vocab_vector\n",
    "    for token in summary_tokens:\n",
    "        if token in fixed_vocab_word_to_index:\n",
    "            y_rep.append(fixed_vocab_word_to_index[token])\n",
    "        else:\n",
    "            y_rep.append(fixed_vocab_word_to_index['<UNK>'])\n",
    "           \n",
    "    resolution_bools.append(all_bill_info[bid]['resolution'])\n",
    "    \n",
    "    ## this is a new addition from before, including longer summaries, but just cutting off the text\n",
    "    if len(y_rep) > 100: # simply cutoff to the first 101 tokens\n",
    "        y_rep = y_rep[:101]\n",
    "    else: # append a end-of-sentence indicator\n",
    "        y_rep.append(fixed_vocab_word_to_index['<SENT>'])\n",
    "    \n",
    "    loss_mask_rep = [1 for i in range(len(y_rep))]\n",
    "    decoder_x_rep = [1]+y_rep[0:len(y_rep)-1] # embedding word in input but not in fixed_vocab is currently set to <UNK>\n",
    "    amount_to_pad = 101-len(y_rep) # 100+1 represents final <SENT> prediction\n",
    "    y_rep += [0 for i in range(amount_to_pad)]\n",
    "    loss_mask_rep += [0 for i in range(amount_to_pad)] # cancels out loss contribution from padding\n",
    "    decoder_x_rep += [0 for i in range(amount_to_pad)]\n",
    "    \n",
    "    # creating joint-probability representation of output:\n",
    "    non_vocab_dict = x_indices_dicts[bid_i]\n",
    "    y_indices_rep = []\n",
    "    for token in summary_tokens:\n",
    "        if token in fixed_vocab_word_to_index: # word is in fixed_vocabulary\n",
    "            y_indices_rep.append(fixed_vocab_word_to_index[token])\n",
    "        elif token in non_vocab_dict: # word is OOV but in the input utterances, use the index assigned to this word in x_indices\n",
    "            y_indices_rep.append(non_vocab_dict[token])\n",
    "        else: # word is OOV and not in input utterances\n",
    "            y_indices_rep.append(fixed_vocab_word_to_index[\"<UNK>\"])\n",
    "            total_oov_words += 1\n",
    "            \n",
    "    if len(y_indices_rep) > 100: # simply cutoff to the first 101 tokens\n",
    "        y_indices_rep = y_indices_rep[:101]\n",
    "    else: # if len <= 100, last prediction should be <SENT>\n",
    "        y_indices_rep.append(fixed_vocab_word_to_index['<SENT>'])\n",
    "    \n",
    "    y_indices_rep += [0 for i in range(amount_to_pad)] # padding will be ignored by loss_mask\n",
    "    y.append(y_rep)\n",
    "    loss_mask.append(loss_mask_rep)\n",
    "    decoder_x.append(decoder_x_rep)\n",
    "    y_indices.append(y_indices_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 500) (5900, 500) (5900, 500)\n",
      "(5900, 101) (5900, 101) (5900, 101)\n",
      "(5900, 50) (5900, 50) (5900, 50)\n",
      "(5900,) 5900\n"
     ]
    }
   ],
   "source": [
    "x = np.array(x).astype(\"int32\")\n",
    "x_indices = np.array(x_indices).astype(\"int32\")\n",
    "att_mask = np.array(att_mask).astype(\"float32\")\n",
    "loss_mask = np.array(loss_mask).astype(\"float32\")\n",
    "decoder_x = np.array(decoder_x).astype(\"int32\")\n",
    "y_indices = np.array(y_indices).astype(\"int32\")\n",
    "utterance_att_masks = np.array(utterance_att_masks).astype(\"float32\")\n",
    "utterance_indices = np.array(utterance_indices).astype(\"int32\")\n",
    "utterance_lengths = np.array(utterance_lengths).astype(\"int32\")\n",
    "print(x.shape,x_indices.shape,att_mask.shape) \n",
    "print(loss_mask.shape,decoder_x.shape,y_indices.shape)\n",
    "print(utterance_att_masks.shape,utterance_indices.shape,utterance_lengths.shape)\n",
    "\n",
    "bids = np.array(bids)\n",
    "print(bids.shape,len(bill_information_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling the data so that only bills are in the validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(856, 500) (856, 101) (856,) (856, 50)\n",
      "(5044, 500) (5044, 101) (5044,) (5044, 50)\n"
     ]
    }
   ],
   "source": [
    "x_resolution = x[resolution_bools]\n",
    "x_indices_resolution = x_indices[resolution_bools]\n",
    "att_mask_resolution = att_mask[resolution_bools]\n",
    "loss_mask_resolution = loss_mask[resolution_bools]\n",
    "decoder_x_resolution = decoder_x[resolution_bools]\n",
    "y_indices_resolution = y_indices[resolution_bools]\n",
    "bids_resolution = bids[resolution_bools]\n",
    "utterance_att_masks_resolution = utterance_att_masks[resolution_bools]\n",
    "utterance_indices_resolution = utterance_indices[resolution_bools]\n",
    "utterance_lengths_resolution = utterance_lengths[resolution_bools]\n",
    "\n",
    "bill_bools = [not res_bool for res_bool in resolution_bools] # reversal\n",
    "x_bill = x[bill_bools]\n",
    "x_indices_bill = x_indices[bill_bools]\n",
    "att_mask_bill = att_mask[bill_bools]\n",
    "loss_mask_bill = loss_mask[bill_bools]\n",
    "decoder_x_bill = decoder_x[bill_bools]\n",
    "y_indices_bill = y_indices[bill_bools]\n",
    "bids_bill = bids[bill_bools]\n",
    "utterance_att_masks_bill = utterance_att_masks[bill_bools]\n",
    "utterance_indices_bill = utterance_indices[bill_bools]\n",
    "utterance_lengths_bill = utterance_lengths[bill_bools]\n",
    "\n",
    "print(x_resolution.shape,loss_mask_resolution.shape,bids_resolution.shape,utterance_att_masks_resolution.shape)\n",
    "print(x_bill.shape,loss_mask_bill.shape,bids_bill.shape,utterance_att_masks_bill.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 500) (400, 101) (400,) (400, 50)\n",
      "(4644, 500) (4644, 101) (4644,) (4644, 50)\n"
     ]
    }
   ],
   "source": [
    "# shuffling only the bill data - in order to get the validation and val set data\n",
    "x_bill,x_indices_bill,att_mask_bill,loss_mask_bill,decoder_x_bill,y_indices_bill,bids_bill,utterance_att_masks_bill,utterance_indices_bill,utterance_lengths_bill = shuffle(x_bill,x_indices_bill,att_mask_bill,loss_mask_bill,decoder_x_bill,y_indices_bill,bids_bill,utterance_att_masks_bill,utterance_indices_bill,utterance_lengths_bill,random_state=1)\n",
    "x_bill_val,x_indices_bill_val,att_mask_bill_val,loss_mask_bill_val,decoder_x_bill_val,y_indices_bill_val,bids_bill_val,utterance_att_masks_bill_val,utterance_indices_bill_val,utterance_lengths_bill_val = x_bill[:400],x_indices_bill[:400],att_mask_bill[:400],loss_mask_bill[:400],decoder_x_bill[:400],y_indices_bill[:400],bids_bill[:400],utterance_att_masks_bill[:400],utterance_indices_bill[:400],utterance_lengths_bill[:400]\n",
    "x_bill_train,x_indices_bill_train,att_mask_bill_train,loss_mask_bill_train,decoder_x_bill_train,y_indices_bill_train,bids_bill_train,utterance_att_masks_bill_train,utterance_indices_bill_train,utterance_lengths_bill_train = x_bill[400:],x_indices_bill[400:],att_mask_bill[400:],loss_mask_bill[400:],decoder_x_bill[400:],y_indices_bill[400:],bids_bill[400:],utterance_att_masks_bill[400:],utterance_indices_bill[400:],utterance_lengths_bill[400:]\n",
    "print(x_bill_val.shape,loss_mask_bill_val.shape,bids_bill_val.shape,utterance_att_masks_bill_val.shape)\n",
    "print(x_bill_train.shape,loss_mask_bill_train.shape,bids_bill_train.shape,utterance_att_masks_bill_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 500) (5500, 101) (5500,) (5500, 50)\n"
     ]
    }
   ],
   "source": [
    "## to remove resolutions, simply don't include them here\n",
    "# shuffling the training set - which is a combination of bill and resolution data\n",
    "x_train = np.vstack([x_bill_train,x_resolution])\n",
    "x_indices_train = np.vstack([x_indices_bill_train,x_indices_resolution])\n",
    "att_mask_train = np.vstack([att_mask_bill_train,att_mask_resolution])\n",
    "loss_mask_train = np.vstack([loss_mask_bill_train,loss_mask_resolution])\n",
    "decoder_x_train = np.vstack([decoder_x_bill_train,decoder_x_resolution])\n",
    "y_indices_train = np.vstack([y_indices_bill_train,y_indices_resolution])\n",
    "bids_train = np.concatenate([bids_bill_train,bids_resolution])\n",
    "\n",
    "utterance_att_masks_train = np.vstack([utterance_att_masks_bill_train,utterance_att_masks_resolution])\n",
    "utterance_indices_train = np.vstack([utterance_indices_bill_train,utterance_indices_resolution])\n",
    "utterance_lengths_train = np.vstack([utterance_lengths_bill_train,utterance_lengths_resolution])\n",
    "\n",
    "x_train,x_indices_train,att_mask_train,loss_mask_train,decoder_x_train,y_indices_train,utterance_att_masks_train,utterance_indices_train,utterance_lengths_train = shuffle(x_train,x_indices_train,att_mask_train,loss_mask_train,decoder_x_train,y_indices_train,utterance_att_masks_train,utterance_indices_train,utterance_lengths_train,random_state=2)\n",
    "print(x_train.shape,loss_mask_train.shape,bids_train.shape,utterance_att_masks_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 500) (5900, 101) (5900,) (5900, 50)\n"
     ]
    }
   ],
   "source": [
    "# adding all the data together, with the final 400 instances being the val and test sets\n",
    "x_final = np.vstack([x_train,x_bill_val])\n",
    "x_indices_final = np.vstack([x_indices_train,x_indices_bill_val])\n",
    "att_mask_final = np.vstack([att_mask_train,att_mask_bill_val])\n",
    "loss_mask_final = np.vstack([loss_mask_train,loss_mask_bill_val])\n",
    "decoder_x_final = np.vstack([decoder_x_train,decoder_x_bill_val])\n",
    "y_indices_final = np.vstack([y_indices_train,y_indices_bill_val])\n",
    "bids_final = np.concatenate([bids_train,bids_bill_val])\n",
    "\n",
    "utterance_att_masks_final = np.vstack([utterance_att_masks_train,utterance_att_masks_bill_val])\n",
    "utterance_indices_final = np.vstack([utterance_indices_train,utterance_indices_bill_val])\n",
    "utterance_lengths_final = np.vstack([utterance_lengths_train,utterance_lengths_bill_val])\n",
    "\n",
    "print(x_final.shape,loss_mask_final.shape,bids_final.shape,utterance_att_masks_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## there is no final shuffling, as the last 400 datapoints represent the validation/test sets\n",
    "subdir = \"len_500_data\"\n",
    "np.save(\"../data/{}/x_500.npy\".format(subdir),x_final)\n",
    "np.save(\"../data/{}/x_indices_500.npy\".format(subdir),x_indices_final)\n",
    "np.save(\"../data/{}/att_mask_500.npy\".format(subdir),att_mask_final)\n",
    "np.save(\"../data/{}/loss_mask_500.npy\".format(subdir),loss_mask_final)\n",
    "np.save(\"../data/{}/decoder_x_500.npy\".format(subdir),decoder_x_final)\n",
    "np.save(\"../data/{}/y_indices_500.npy\".format(subdir),y_indices_final)\n",
    "np.save(\"../data/{}/bids_500.npy\".format(subdir),bids_final)\n",
    "\n",
    "np.save(\"../data/{}/utterance_att_mask_500.npy\".format(subdir),utterance_att_masks_final)\n",
    "np.save(\"../data/{}/utterance_indices_500.npy\".format(subdir),utterance_indices_final)\n",
    "np.save(\"../data/{}/utterance_lengths_500.npy\".format(subdir),utterance_lengths_final)\n",
    "\n",
    "with open(\"../data/len_500_data/bill_information.json\",\"w+\") as out_file:\n",
    "    json.dump(bill_information_dict,out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
