### Random Machine Learning Projects/Implementations

Projects/Implementations, each with a varying level of clear documentation and algorithmic efficiency.

#### All descriptions: 
- dino_runner_yolo: YOLO model implementation to detect whether a user's palm is open or closed (based on personal data), and separate driver program that feeds commands to play the Chrome dinosaur game using Selenium.
- trigger_word_detector: Unidirectional multilayered RNN model to detect when a trigger word is said (based on personal data and heavy data synthesis), and separate driver program using multithreading to detect utterances on the fly.
- pointer-gen_implementations: Various implementations of pointer-generator networks & beam search.
- generative_adversarial_nets: 
  1. Standard GAN implementation for digit generation.
  2. Conditional LSGAN.
  3. Energy-based GAN, vanilla and with PT component.
  4. Wasserstein GAN, vanilla and using GP.
  5. Pix2Pix conditional GAN.
  6. Cycle GAN.
- deep_learning_for_nlp:
  1. Variants of the Pointer-Generator network for news title summarization, including vanilla, hierarchical, and transformer-based.
  2. Convolutional Seq2Seq model implementation.
  3. Implementation of a RNN with an attention mechanism.
  4. Vanilla Transformer implementation.
  5. Skip-Gram word embeddings using negative & importance sampling.
  6. ByteNet Character-level translation model.
- domain_adaptation:
  1. Subspace alignment.
  2. Domain adversarial neural networks.
  3. Domain adaptation with GANs.
  4. Deep domain confusion.
  5. Deep CORAL.
- adversarial_methods:
  1. Simple adversarial attack with DNN.
  2. Fast gradient sign method.
  3. Traditional adversarial regularization.
  4. Virtual adversarial regularization.
- bayesian_methods:
  1. Gaussian Process regression.
- other_models_and_work:
  1. Pointer Network for solving convex hull.
  2. Joint-siamese model for NLP.
  3. Highway network.
  4. Iterative feature expansion to reduce feature sparsity.
  5. TF-IDF variant based on clustering for short text data.
  6. Loss truncation as a proxy for distinguishability.
- autoencoders: 
  1. DNN/CNN auto-encoders for denoising with MNIST.
  2. variational auto-encoder for generation with MNIST.
  3. stacked denoising auto-encoder for domain adaptation.
- computer_vision:
  1. Neural style transfer ([Video](https://www.linkedin.com/posts/nathaniel-andre_computervision-deeplearning-activity-6484430196412944384-Zjj3)).
  2. Facial recognition implementation based on FaceNet.
  3. GoogLeNet Tensorflow implementation.
  4. Resnet-50 implementation in Keras and Tensorflow.
- clustering: 
  1. K-means clustering implementation.
  2. DBSCAN density clustering implementation.
  3. Gaussian mixture model.
- anomaly_detection: 
  1. Gaussian anomaly detection w/ multivariate and univariate implementations.
  2. Mahalanobis distance implementation.
- recommender_systems: 
  1. Collaborative filtering implementation.
- language_models: 
  1. Character level RNN for Goethe's Wilhelm Meister.
  2. Word level CNN with Gated Linear Units for Melville's Moby-Dick.
- genetic_algorithm:
  1. Simple instance of a genetic algorithm to find parameters that maximize a simple objective function.
  2. Simple genetic algorithm to learn how to play an implementation of the snake game.
- simple_models:
  1. kernel regression: gaussian kernel, gradient hyperparameter search, and bootstrapped prediction intervals.
  2. svm: SVM implementation using simple gradient descent, for linear and gaussian kernels.
  3. dense_neural_net: Simple neural network with hidden layers and sigmoid/relu activation, xavier initialization, and adam optimization implementations.
  4. linear_regression: Linear regression implementation using gradient descent.
  5. logistic_regression: Logistic regression implementation using gradient descent.
  6. naive_bayes: Bayesian classification model based on gaussian likelihood.
