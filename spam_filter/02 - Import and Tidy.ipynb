{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h1>IMPORT AND TIDYING</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is focused on cleaning each email to extract only the most important information from all of the emails and then creating a comprehensive dataset. For each email, a series of \"cleaner\" functions are called to extract information, which is then used to create a dictionary for each email. This continues until all emails have been cleaned, and associated information is stored in a list of dictionaries. \n",
    "\n",
    "An important part of this cleaning involves using natural language processing to extract unique keywords from all of the emails. An extensive file of stop words is used to determine whether any particular keyword should be ignored or not. Once the keywords are extracted, I use them to build up a database of spam scores associated with each email. These values are then assigned to each email.\n",
    "\n",
    "With these steps complete, I then began testing whether there were any encoding errors when processing the emails. I then handled these by filling in empty values with appropriate information and dropping certain rows of data. This developed dataset is then used in the remainder of my project.\n",
    "\n",
    "NOTE: All testing of cleaning functions was done through sampling emails and comparing the output of the function calls to the desired values to be extracted from the emails. Test cases at the end ensure that the dataset has been properly created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email.parser\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS  # These are a list of common stop words.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h3> Extracting Spam and Ham (Not Spam) values </h3>\n",
    "\n",
    "To begin cleaning the emails, I imported the test file which classifies all of the emails as either Spam or Ham. I used this to create an easy to use dictionary to classify any given email as spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary of email classifications.\n",
    "\n",
    "This function takes in a text file which classifies all of the labeled emails as being spam or not. It then outputs a dictionary that is used to show the classification for each email.\n",
    "\"\"\"\n",
    "def classify(txt_file):\n",
    "    cl = {}\n",
    "    with open(txt_file) as txt:\n",
    "        lines = txt.readlines()\n",
    "        for line in lines: \n",
    "            temp = line.replace('\\n', '').split(' ')\n",
    "            cl[temp[1]] = int(temp[0])\n",
    "    return cl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl is the dictionary that contains the spam classification for all of the emails.\n",
    "\n",
    "cl = classify('/data/thenateandre/CSDMC2010_SPAM/CSDMC2010_SPAM/SPAMTrain.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_00001.eml 0\n",
      "TRAIN_00002.eml 1\n",
      "TRAIN_00003.eml 0\n",
      "TRAIN_00004.eml 0\n"
     ]
    }
   ],
   "source": [
    "# This short snippet of cl shows each email and whether it is spam or not (0 is spam and 1 is not spam).\n",
    "\n",
    "keys = list(cl.keys())\n",
    "for i in range(1, 5):\n",
    "    print(keys[i], cl[keys[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h2> Cleaning and Tidying </h2>\n",
    "\n",
    "The functions in this next section are used to clean and extract all of the important attributes from each email. This includes attributes such as day and hour the email was sent, sender, whether there is a subscribe option, keywords in the emails, whether the sender used mailer software, and much more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Extracts all the relevant information from the email and returns a list of dictionaries (each dictionary representing a unique email).\n",
    "\n",
    "This function takes in a dictionary of all of the files with labels for whether an email is spam and extracts the important contents from each of the emails. This function then returns a list of dictionaries, with each dictionary representing one email.\n",
    "\"\"\"\n",
    "def email_extract(cl):\n",
    "    global count\n",
    "    lis_of_emails = []\n",
    "    for email in cl.keys():\n",
    "        # Getting the values for one particular email:\n",
    "        temp = extract_values(email, cl[email])\n",
    "        lis_of_emails.append(temp)\n",
    "    return lis_of_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns the dictionary of email attributes for each individual email.\n",
    "\n",
    "This function calls an assortment of other \"cleaning\" functions that extract and clean all of the relevant data from the emails and stores it in a dictionary for each of the emails.\n",
    "\"\"\"\n",
    "def extract_values(file_name, label):\n",
    "    return_dic = {}\n",
    "    # Opening each file and calling cleaning functions on the contents of the emails.\n",
    "    with open('/data/thenateandre/CSDMC2010_SPAM/CSDMC2010_SPAM/TRAINING/'+file_name, 'rb') as fp:\n",
    "        msg = email.message_from_binary_file(fp)\n",
    "        payload = msg.get_payload()\n",
    "        # Building the dictionary:\n",
    "        return_dic['email'] = file_name\n",
    "        return_dic['label'] = label\n",
    "        return_dic['receive_count'] = msg.keys().count('Received')  # Counts how many servers the email went through.\n",
    "        return_dic = clean_date_time(msg['Date'], return_dic)\n",
    "        return_dic = clean_main_attributes(msg['From'], msg['Content-Type'], return_dic)\n",
    "        return_dic = clean_other_attributes(msg['MIME-Version'], msg['List-Subscribe'], msg['List-Unsubscribe'], return_dic)\n",
    "        return_dic = clean_x_attributes(msg['X-mailer'], msg['X-priority'], return_dic)\n",
    "        return_dic = subject_message_handler(msg['Subject'], return_dic)  # Subject line.\n",
    "        # Main message body handler:\n",
    "        if type(payload) == type(list()):\n",
    "            try:  # Handles improper email encoding errors.\n",
    "                return_dic = main_message_handler_alternative(str(payload[0]), str(payload[1]), return_dic)  # payload[1] includes any html attributes.\n",
    "            except:\n",
    "                return_dic['message'] = None\n",
    "        else:\n",
    "            return_dic = main_message_handler(str(payload), return_dic)\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h3> Natural Language Processing </h3>\n",
    "\n",
    "This section of cleaning and tidying functions are focused on the main message and subject lines for the emails. The functions are primarily focused on using NLP and an extensive list of stop words to extract relevant keywords from the subject line and main email message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Spacy as the natural language processor.\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Takes in a dictionary and an email's subject-line and details whether an email has 're:' in the subject-line, along with adding the subject-line keywords.\n",
    "\n",
    "This function adds one if the email subject-line has 're:' in it and also adds the subject-line keywords to the dictionary after they have been cleaned. \n",
    "\"\"\"\n",
    "def subject_message_handler(subject, return_dic):\n",
    "    lowered = str(subject).lower()\n",
    "    if 're:' in lowered:\n",
    "        return_dic['re'] = 1\n",
    "    else:\n",
    "        return_dic['re'] = 0\n",
    "    subject = tokenizer(list(nlp(lowered)))  # Calling the rokenizer helper function to clean keyword list.\n",
    "    return_dic['subject_line'] = list(subject)\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Takes in a dictionary and an email's main message and adds the important keywords to the dictionary along with whether html was being used and returns the dictionary.\n",
    "\n",
    "This function is the main message handler, meaning it handles \"type A\" emails, that are less likely to have encoding errors. These emails also still contain html attributes.\n",
    "\"\"\"\n",
    "def main_message_handler(message, return_dic):\n",
    "    # HTML tag handler to determine whether html tags are being used:\n",
    "    message = message.lower()  # Making sure all words are lower case before analysis.\n",
    "    if \"<html>\" in message or \"<head>\" in message or \"<body>\" in message:\n",
    "        return_dic['html_use'] = 1\n",
    "    else:\n",
    "        return_dic['html_use'] = 0\n",
    "    # NLP used to determine content of message:\n",
    "    content = tokenizer(list(nlp(message)))\n",
    "    return_dic['message'] = list(content)\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Takes in a dictionary and two forms of the email (one with html attributes and one without), and adds the important keywords to the dictionary along with whether html was being used, and returns the dictionary.\n",
    "\n",
    "This is used for separate encodings of the main message for \"type B\" emails, meaning the emails have potentially more encoding errors.\n",
    "\"\"\"\n",
    "def main_message_handler_alternative(message, html_message, return_dic):\n",
    "    # HTML tag handler to determine whether html tags are being used:\n",
    "    html_message = html_message.lower()  # Making sure all words are lower case before analysis.\n",
    "    if \"<html>\" in html_message or \"<head>\" in html_message or \"<body>\" in html_message:\n",
    "        return_dic['html_use'] = 1\n",
    "    else:\n",
    "        return_dic['html_use'] = 0\n",
    "    # NLP to determine content of message:\n",
    "    content = tokenizer(list(nlp(message.lower())))\n",
    "    return_dic['message'] = list(content)\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Takes in a list of keyword tokens and returns only relevent keywords.\n",
    "\n",
    "This helper function determines whether a keyword is a stop word and whether it is significant. \n",
    "\"\"\"\n",
    "def tokenizer(text):\n",
    "    return_lis = []\n",
    "    for token in text:\n",
    "        # Determining if keyword is a stop word:\n",
    "        if str(token) not in stop_words and str(token).isalpha():\n",
    "            return_lis.append(token)\n",
    "    return return_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a comprehensive list of stop words from Spacy suggestions to words pulled from the internet.\n",
    "\n",
    "stop_words = []\n",
    "with open('/data/thenateandre/CSDMC2010_SPAM/CSDMC2010_SPAM/stop_word.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.replace(\"\\n\", '')\n",
    "        if line not in stop_words:\n",
    "            stop_words.append(line)\n",
    "    # Stop words from spacy.\n",
    "    for word in STOP_WORDS:\n",
    "        if word not in STOP_WORDS:\n",
    "            stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'above', 'abroad', 'according', 'accordingly', 'across', 'actually', 'adj', 'after', 'afterwards']\n"
     ]
    }
   ],
   "source": [
    "# These are examples of some of stop words:\n",
    "\n",
    "print(stop_words[20:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of these functions are used to gather and clean data from the other attributes of each email\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h3> Cleaning the Rest of the Email Attributes </h3>\n",
    "\n",
    "After processing the keywords and attributes of the subject-line and main message portions of all of the emails, I moved on to cleaning the rest of the important attributes of the emails. These include whether mailer software was used to send the email, the priority of the email set, and other attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary that includes the important x-values of the emails.\n",
    "\n",
    "Determines whether the sender of the email was using mailer software, and if they set a priority for their email.\n",
    "\"\"\"\n",
    "def clean_x_attributes(mailer, priority, return_dic):\n",
    "    # Cleaning X-priority values:\n",
    "    if priority is not None:\n",
    "        return_dic['X-Priority'] = int(float(priority.split(' ')[0].replace(\"'\", \"\")))\n",
    "    else:\n",
    "        return_dic['X-Priority'] = 3  # 3 is the standard value of the priority attribute if not specified.\n",
    "    # Cleaning X-mailer string values:\n",
    "    if mailer is not None:\n",
    "        return_dic['X-Mailer'] = 1\n",
    "    else:\n",
    "        return_dic['X-Mailer'] = 0\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary that includes message id, mime, subscribe, and unsubscribe attributes of the emails. \n",
    "\n",
    "This function takes three other attributes from the emails. It cleans the values and ensures that there will not be a cardinality problem.\n",
    "\"\"\"\n",
    "def clean_other_attributes(mime, subscribe, unsubscribe, return_dic):\n",
    "    # Cleaning MIME values:\n",
    "    if mime is not None:\n",
    "        return_dic['MIME-Version'] = 1  # Represents True.\n",
    "    else:\n",
    "        return_dic['MIME-Version'] = 0\n",
    "    # Cleaning Subscribe values:\n",
    "    if subscribe is not None:\n",
    "        return_dic['Subscribe'] = 1\n",
    "    else:\n",
    "        return_dic['Subscribe'] = 0\n",
    "    # Cleaning unsubscribe values:\n",
    "    if unsubscribe is not None:\n",
    "        return_dic['Unsubscribe'] = 1\n",
    "    else:\n",
    "        return_dic['Unsubscribe'] = 0\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary with the cleaned values of the sender and content_type attributes of an email.\n",
    "\n",
    "This function determines whether there is a content_type and who the sender is. It cleans the sender attribute of the email such that there is a section focused on the trailing section of the email handle such as 'com' or 'net'.\n",
    "\"\"\"\n",
    "def clean_main_attributes(sender, content_type, return_dic):\n",
    "    # Cleaning content_type:\n",
    "    if content_type is not None:\n",
    "        return_dic['content-type'] = str(content_type).split(';')[0]\n",
    "    else:\n",
    "        return_dic['content-type'] = 'None'\n",
    "    # Cleaning the sender:\n",
    "    if '<' in str(sender) or '>' in str(sender):\n",
    "        sender = str(sender).replace('>', '').replace('<', '').replace('\"', '').split(' ')\n",
    "    else:\n",
    "        sender = str(sender).replace('\"', '').split(' ')\n",
    "    var = 0  # We are ignoring the first word (name of sender).\n",
    "    for i in sender:\n",
    "        if ('@' in i and var != 0) or ('@' in i and len(sender) == 1):\n",
    "            return_dic['from_full'] = i\n",
    "            # Cleaning the sender attribute for low cardinality:\n",
    "            fro = i.split(\".\")\n",
    "            if len(fro) > 1:  # If there is a sender:\n",
    "                return_dic['from'] = fro[-1]\n",
    "            else:  # Handles no sender.\n",
    "                return_dic['from'] = None\n",
    "            break\n",
    "        var += 1\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary with the cleaned time and day values.\n",
    "\n",
    "This function focuses on getting the day and time values of when the email was sent and then ensuring that these values won't have a cardinality problem.\n",
    "\"\"\"\n",
    "def clean_date_time(date_val, return_dic):\n",
    "    try:\n",
    "        if date_val is not None:  # If there is actually a date value.\n",
    "            date_temp = str(date_val).replace(',', '').split(' ')\n",
    "            # Conditional logic dependent on whether the day is included in the Date email attribute.\n",
    "            if ord(date_temp[0][0]) > 64:  # There is a day of the week.\n",
    "                day = date_temp[0].lower()\n",
    "                return_dic = day_sep(day, return_dic)\n",
    "                hour = date_temp[4].split(':')[0]\n",
    "                if (date_temp[5]):  # If there is a time zone adjustment.\n",
    "                    if '-' in date_temp[5]:\n",
    "                        fin_hour = int(hour) + int(date_temp[5].split('-')[1]) / 100\n",
    "                    else: \n",
    "                        fin_hour = int(hour) - int(date_temp[5].split('+')[1]) / 100\n",
    "                    return_dic = time_of_day_sep(fin_hour, return_dic)\n",
    "                else:\n",
    "                    return_dic = time_of_day_sep(hour, return_dic)\n",
    "            else:\n",
    "                day = datetime(int(date_temp[2]), datetime.strptime((date_temp[1]), '%b').month, int(date_temp[0])).strftime('%a').lower()\n",
    "                return_dic = day_sep(day, return_dic)\n",
    "                hour = date_temp[3].split(':')[0]\n",
    "                if (date_temp[4]):\n",
    "                    if '-' in date_temp[4]:\n",
    "                        fin_hour = int(hour) + int(date_temp[4].split('-')[1]) / 100\n",
    "                    else: \n",
    "                        fin_hour = int(hour) - int(date_temp[4].split('+')[1]) / 100\n",
    "                    return_dic = time_of_day_sep(fin_hour, return_dic)\n",
    "                else:\n",
    "                    return_dic = time_of_day_sep(hour, return_dic)\n",
    "            return return_dic\n",
    "        else:\n",
    "            return_dic['hour'] = None\n",
    "            return_dic['day'] = None\n",
    "            return return_dic\n",
    "    except:\n",
    "        return_dic['hour'] = None\n",
    "        return_dic['day'] = None\n",
    "        return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary with the value of an hour in integer form.\n",
    "\n",
    "This function is focused on decreasing the cardinality problem for hour values.\n",
    "\"\"\"\n",
    "def time_of_day_sep(hour, return_dic):\n",
    "    if hour > 24:\n",
    "        hour = hour - 24\n",
    "    if hour >= 0 and hour < 4:\n",
    "        return_dic['hour'] = 0\n",
    "    elif hour >= 4 and hour < 8:\n",
    "        return_dic['hour'] = 1\n",
    "    elif hour >= 8 and hour < 12:\n",
    "        return_dic['hour'] = 2\n",
    "    elif hour >= 12 and hour < 16:\n",
    "        return_dic['hour'] = 3\n",
    "    elif hour >= 16 and hour < 20:\n",
    "        return_dic['hour'] = 4\n",
    "    elif hour >= 20 and hour <= 24:\n",
    "        return_dic['hour'] = 5\n",
    "    else:\n",
    "        return_dic['hour'] = None\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary with the value of a day in integer form.\n",
    "\n",
    "This function is focused on decreasing the cardinality problem for day values.\n",
    "\"\"\"\n",
    "def day_sep(day, return_dic):\n",
    "    if day == 'sun':\n",
    "        return_dic['day'] = 0\n",
    "    elif day == 'mon':\n",
    "        return_dic['day'] = 1\n",
    "    elif day == 'tue':\n",
    "        return_dic['day'] = 2\n",
    "    elif day == 'wed':\n",
    "        return_dic['day'] = 3\n",
    "    elif day == 'thu':\n",
    "        return_dic['day'] = 4\n",
    "    elif day == 'fri':\n",
    "        return_dic['day'] = 5\n",
    "    elif day == 'sat':\n",
    "        return_dic['day'] = 6\n",
    "    else:\n",
    "        return_dic['day'] = None\n",
    "    return return_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this point, the remaining effort is put into improving the dataset and adding other important predictive variables to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not re-run this. This takes more than a few minutes.\n",
    "# This is the list of dictionaries that represents all emails and their attributes (with everything cleaned).\n",
    "\n",
    "email_content = email_extract(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h2> Spam Keyword Database and Bayesian Spam Classifier </h2>\n",
    "\n",
    "After cleaning the keywords from all of the emails, I began to build up my database with all of the mined keywords. The database is a python dictionary that contains the following attributes for any given keyword:\n",
    "\n",
    "1. Count of how many spam emails the keyword shows up in.\n",
    "2. Count of how many ham emails the keyword shows up in.\n",
    "3. Total count of how many times the keyword showed up.\n",
    "\n",
    "These counts are then used to assign a value of \"spaminess\" to any given keyword. This is done through an equation I outline later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h3> Spam Keyword Database </h3>\n",
    "\n",
    "As specified above, these next two functions are being used to create the spam keyword database. Only the first occurrence of a keyword for any given email will be included in the database (thus no double counting, which would decrease the accuracy of any analysis using the database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code creates the keyword database, which includes all of the keywords from the emails.\n",
    "\n",
    "keyword_data = {}\n",
    "\n",
    "for email in email_content:\n",
    "    temp_list = []\n",
    "    # Handler for missing message body or subject_line.\n",
    "    if email['subject_line'] is not None and email['message'] is not None:\n",
    "        email_keywords = email['subject_line'] + email['message']\n",
    "    elif email['subject_line'] is not None:\n",
    "        email_keywords = email['subject_line']\n",
    "    else:\n",
    "        email_keywords = email['message']\n",
    "    email_keywords_str = []\n",
    "    # This changes the dictionary from spacy tokens to strings.\n",
    "    for i in email_keywords:\n",
    "        email_keywords_str.append(str(i))\n",
    "    # Making sure that only unique values are present:\n",
    "    for keyw in email_keywords_str:\n",
    "        if keyw not in temp_list:\n",
    "            temp_list.append(keyw)\n",
    "    # Actual creation of the keyword_data dictionary:\n",
    "    keyword_data = keyword_parser(email, temp_list, keyword_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Takes in and returns a dictionary representing the spam keyword database, with additional keyword entries.\n",
    "\n",
    "This helper function helps create the spam keyword database through handling actually adding values to the database.\n",
    "\"\"\"\n",
    "def keyword_parser(email, keywords, keyword_data):\n",
    "    for word in keywords:\n",
    "        if word in keyword_data.keys():  # If the keyword is already in the dictionary.                \n",
    "            if email['label'] == 1:  # Not spam.\n",
    "                keyword_data[word]['ham'] += 1 \n",
    "            else:  # Is spam.\n",
    "                keyword_data[word]['spam'] += 1\n",
    "            keyword_data[word]['total_count'] += 1\n",
    "        else:  # The word is not in the dictionary.\n",
    "            keyword_data[word] = {'ham':0, 'spam':0, 'total_count':0}\n",
    "            if email['label'] == 1:\n",
    "                keyword_data[word]['ham'] += 1\n",
    "            else:\n",
    "                keyword_data[word]['spam'] += 1\n",
    "            keyword_data[word]['total_count'] += 1\n",
    "    return keyword_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51723"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the total count of keywords:\n",
    "\n",
    "len(keyword_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> kind\n",
      "<class 'str'> money\n",
      "<class 'str'> maker\n",
      "<class 'str'> free\n",
      "<class 'str'> link\n",
      "<class 'str'> webcam\n",
      "<class 'str'> wanted\n",
      "<class 'str'> wanna\n",
      "<class 'str'> sexually\n",
      "<class 'str'> curious\n",
      "<class 'str'> teens\n"
     ]
    }
   ],
   "source": [
    "# These are some of the keywords in the database:\n",
    "\n",
    "keys = keyword_data.keys()\n",
    "count = 0\n",
    "for i in keys:\n",
    "    if count <= 10:\n",
    "        print(type(i), i)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h3> Bayesian Spam Classifier </h3>\n",
    "\n",
    "With the spam keyword database created, I then began to assign a \"spamminess\" score to each of the keywords, indicating whether it has a high or low probability of being associated with spam emails. The equation used to compute this score is showcased below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{spam}(token) = \\frac{\\frac{n_{spam}(token)}{n_{spam}}}{\\frac{n_{spam}(token)}{n_{spam}}+\\frac{n_{ham}(token)}{n_{ham}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2949, 1378)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of spam and nonspam emails used for later analysis.\n",
    "\n",
    "total_ham = 0\n",
    "total_spam = 0\n",
    "\n",
    "spam_counts = list(cl.values())\n",
    "for val in spam_counts:\n",
    "    if val == 0:\n",
    "        total_spam += 1\n",
    "    elif val == 1:\n",
    "        total_ham += 1\n",
    "total_ham, total_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spam score for every entry in the spam dictionary. High value indicates a \"spammy\" keyword.\n",
    "\n",
    "for word in keyword_data.keys():\n",
    "    keyword_data[word]['spam_score'] = ((keyword_data[word]['spam'])/total_spam) / (((keyword_data[word]['spam'])/total_spam) + (((keyword_data[word]['ham'])/total_ham)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 kind\n",
      "{'ham': 141, 'spam': 58, 'total_count': 199, 'spam_score': 0.46817211364756117}\n",
      "277 money\n",
      "{'ham': 107, 'spam': 170, 'total_count': 277, 'spam_score': 0.7727320369434134}\n",
      "23 maker\n",
      "{'ham': 17, 'spam': 6, 'total_count': 23, 'spam_score': 0.4303015564202335}\n",
      "721 free\n",
      "{'ham': 350, 'spam': 371, 'total_count': 721, 'spam_score': 0.6940456578018357}\n",
      "375 link\n",
      "{'ham': 136, 'spam': 239, 'total_count': 375, 'spam_score': 0.7899529151475142}\n",
      "22 webcam\n",
      "{'ham': 15, 'spam': 7, 'total_count': 22, 'spam_score': 0.49967322634521816}\n"
     ]
    }
   ],
   "source": [
    "# This shows some of the counts for the values in the dictionary:\n",
    "\n",
    "counter = 0\n",
    "for word in keyword_data.keys():\n",
    "    if keyword_data[word]['total_count'] > 1:\n",
    "        print(keyword_data[word]['total_count'], word)\n",
    "        print(keyword_data[word])\n",
    "    if counter >= 5:\n",
    "        break\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h3> Using Weighted Average of Keyword Scores to Estimate Email Spamminess </h3>\n",
    "\n",
    "To best leverage the spam scores, I computed with my spam keyword database, I used two distinct averages to assign a \"spamminess\" score to each email. These are:\n",
    "\n",
    "1. Averaging based solely on keyword appearance in the subject-line and main message body.\n",
    "\n",
    "2. Averaging based on keyword appearance in the subject-line and main message body along with using additional weighting based on how many occurances of the keyword there are in the spam keyword database. The though here is that the \"spamminess\" score given to a keyword with more occurances will most likely be more accurate.\n",
    "\n",
    "These are showcased below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Equation 1.\n",
    "\n",
    "$$P_{spam}(email) = \\big[W_{keyword_1} * P_{spam}(keyword_1)\\big] + \\big[W_{keyword_2} * P_{spam}(keyword_2)\\big] +  \\hspace{.25cm}... \\hspace{.1cm}+ \\big[W_{keyword_i} * P_{spam}(keyword_i)\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Equation 2. \n",
    "\n",
    "$$P_{spam}(email) = \\bigg[\\big[W_{keyword_1} * P_{spam}(keyword_1) * Count_{keyword_1} \\big] + \\big[W_{keyword_2} * P_{spam}(keyword_2) * Count_{keyword_2} \\big] +  \\hspace{.25cm}... \\hspace{.1cm}+ \\big[W_{keyword_i} * P_{spam}(keyword_i) * Count_{keyword_i} \\big]\\bigg] \\bigg/ Total Count$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the spam score for every email.\n",
    "# Subject-line and main message body have different scores.\n",
    "# nwas score corresponds with equation 1.\n",
    "# extra score corresponds with equation 2.\n",
    "\n",
    "for email in email_content:\n",
    "    if email['subject_line'] is not None and email['message'] is not None:\n",
    "        if email['subject_line'] != [] and email['message'] != []:\n",
    "            email['subject_line_nwas_score'] = keyword_occurance(email['subject_line'])\n",
    "            email['main_message_nwas_score'] = keyword_occurance(email['message'])\n",
    "            email['subject_line_extra_score'] = keyword_occurance_database(email['subject_line'])\n",
    "            email['main_message_extra_score'] = keyword_occurance_database(email['message']) \n",
    "        elif email['subject_line'] != []:\n",
    "            email['subject_line_nwas_score'] = keyword_occurance(email['subject_line'])\n",
    "            email['main_message_nwas_score'] = None\n",
    "            email['subject_line_extra_score'] = keyword_occurance_database(email['subject_line'])\n",
    "            email['main_message_extra_score'] = None\n",
    "        else:  # Subject line == [].\n",
    "            email['subject_line_nwas_score'] = None\n",
    "            email['main_message_nwas_score'] = keyword_occurance(email['message'])\n",
    "            email['subject_line_extra_score'] = None\n",
    "            email['main_message_extra_score'] = keyword_occurance_database(email['message']) \n",
    "        \n",
    "    elif email['subject_line'] is not None:\n",
    "        if email['subject_line'] != []:\n",
    "            email['subject_line_nwas_score'] = keyword_occurance(email['subject_line'])\n",
    "            email['subject_line_extra_score'] = keyword_occurance_database(email['subject_line'])\n",
    "        else:\n",
    "            email['subject_line_extra_score'] = None\n",
    "            email['subject_line_nwas_score'] = None\n",
    "    else:\n",
    "        if email['message'] != []:\n",
    "            email['main_message_nwas_score'] = keyword_occurance(email['message'])\n",
    "            email['main_message_extra_score'] = keyword_occurance_database(email['message']) \n",
    "        else:\n",
    "            email['main_message_nwas_score'] = None\n",
    "            email['main_message_extra_score'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Takes in a list of keywords and returns the \"nwas\" spam score for a given email.\n",
    "\n",
    "Weight for each score based on weight in email.\n",
    "\"\"\"\n",
    "def keyword_occurance(keywords):\n",
    "    if (len(keywords) != 0):\n",
    "        running_total = 0.0\n",
    "        for keyw in keywords:\n",
    "            score = keyword_data[str(keyw)]['spam_score']\n",
    "            running_total += score\n",
    "        return running_total / len(keywords)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Takes in a list of keywords and returns the \"extra\" spam score for a given email.\n",
    "\n",
    "Weight for each score based on weight in database and weight in email.\n",
    "\"\"\"\n",
    "def keyword_occurance_database(keywords):\n",
    "    if (len(keywords) != 0):\n",
    "        running_denom = 0.0\n",
    "        running_total = 0.0\n",
    "        for keyw in keywords:\n",
    "            score = keyword_data[str(keyw)]['spam_score'] * keyword_data[str(keyw)]['total_count']\n",
    "            running_denom += keyword_data[str(keyw)]['total_count']\n",
    "            running_total += score\n",
    "        return running_total / running_denom # len(keywords)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of emails with unindexable message bodies. \n",
    "# This is relevant because these NaN values in the dataset will need to be accounted for.\n",
    "\n",
    "count = 0\n",
    "for i in email_content:\n",
    "    if i['message'] == None:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <h3> Creating and Cleaning up the Pandas Dataframe </h3>\n",
    "\n",
    "After adding the spam scores for all of the emails, my attention is now on creating a pandas dataframe with my data. Because of the way I processed my emails, this is a relatively easy step. However, I then check to see if there are any values that should not be there, and I handle all NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataframe.\n",
    "\n",
    "email_data_frame = pd.DataFrame(email_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4327"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping values that I don't plan on using in my analysis and renaming certain columns.\n",
    "\n",
    "email_data_frame = email_data_frame.drop(['message', 'subject_line', 'from_full'], axis=1)\n",
    "email_data_frame.rename(columns={'X-Mailer':'Mailer', 'X-Priority':'Priority', 'MIME-Version': 'MIME', 'content-type':'content'}, inplace=True)\n",
    "\n",
    "# Making sure that the 'content' and 'from' columns are encoded correctly with lower case strings:\n",
    "\n",
    "email_data_frame['content'] = email_data_frame['content'].str.lower()\n",
    "email_data_frame['from'] = email_data_frame['from'].str.lower()\n",
    "\n",
    "len(email_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIME</th>\n",
       "      <th>Subscribe</th>\n",
       "      <th>Unsubscribe</th>\n",
       "      <th>Mailer</th>\n",
       "      <th>Priority</th>\n",
       "      <th>content</th>\n",
       "      <th>day</th>\n",
       "      <th>email</th>\n",
       "      <th>from</th>\n",
       "      <th>hour</th>\n",
       "      <th>html_use</th>\n",
       "      <th>label</th>\n",
       "      <th>main_message_extra_score</th>\n",
       "      <th>main_message_nwas_score</th>\n",
       "      <th>re</th>\n",
       "      <th>receive_count</th>\n",
       "      <th>subject_line_extra_score</th>\n",
       "      <th>subject_line_nwas_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>multipart/mixed</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TRAIN_00000.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.591313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN_00001.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789154</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.687633</td>\n",
       "      <td>0.567793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>multipart/signed</td>\n",
       "      <td>6.0</td>\n",
       "      <td>TRAIN_00002.eml</td>\n",
       "      <td>org</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.377856</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.572255</td>\n",
       "      <td>0.465104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN_00003.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842464</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.817109</td>\n",
       "      <td>0.811058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN_00004.eml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.619219</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.786136</td>\n",
       "      <td>0.786136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MIME  Subscribe  Unsubscribe  Mailer  Priority           content  day  \\\n",
       "0     1          0            0       0         3   multipart/mixed  5.0   \n",
       "1     1          0            0       1         1        text/plain  1.0   \n",
       "2     1          1            1       0         3  multipart/signed  6.0   \n",
       "3     1          0            0       1         3        text/plain  2.0   \n",
       "4     0          0            0       0         3              none  2.0   \n",
       "\n",
       "             email from  hour  html_use  label  main_message_extra_score  \\\n",
       "0  TRAIN_00000.eml  com   1.0       NaN      0                       NaN   \n",
       "1  TRAIN_00001.eml  com   0.0       0.0      0                  0.789154   \n",
       "2  TRAIN_00002.eml  org   3.0       0.0      1                  0.463395   \n",
       "3  TRAIN_00003.eml  com   0.0       0.0      0                  0.842464   \n",
       "4  TRAIN_00004.eml  NaN   5.0       0.0      0                  0.753900   \n",
       "\n",
       "   main_message_nwas_score  re  receive_count  subject_line_extra_score  \\\n",
       "0                      NaN   0              2                  0.670096   \n",
       "1                 0.674667   0              8                  0.687633   \n",
       "2                 0.377856   1             11                  0.572255   \n",
       "3                 0.821000   0              7                  0.817109   \n",
       "4                 0.619219   0              4                  0.786136   \n",
       "\n",
       "   subject_line_nwas_score  \n",
       "0                 0.591313  \n",
       "1                 0.567793  \n",
       "2                 0.465104  \n",
       "3                 0.811058  \n",
       "4                 0.786136  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to make sure that all columns have correct values.\n",
    "# All of these columns should not have any possibility of including NaN values. \n",
    "\n",
    "assert not email_data_frame['MIME'].isnull().values.any()\n",
    "assert not email_data_frame['Subscribe'].isnull().values.any()\n",
    "assert not email_data_frame['Unsubscribe'].isnull().values.any()\n",
    "assert not email_data_frame['Mailer'].isnull().values.any()\n",
    "assert not email_data_frame['Priority'].isnull().values.any()\n",
    "assert not email_data_frame['content'].isnull().values.any()\n",
    "assert not email_data_frame['re'].isnull().values.any()\n",
    "assert not email_data_frame['receive_count'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For emails that have either a missing main message or subject line, I am replacing those spam scores with the scores of whichever is not missing.\n",
    "# This is sensible because the scores are coming from the same spam keyword database.\n",
    "\n",
    "email_data_frame['main_message_extra_score'] = email_data_frame['main_message_extra_score'].fillna(email_data_frame['subject_line_extra_score'])\n",
    "email_data_frame['main_message_nwas_score'] = email_data_frame['main_message_nwas_score'].fillna(email_data_frame['subject_line_nwas_score'])\n",
    "email_data_frame['subject_line_extra_score'] = email_data_frame['subject_line_extra_score'].fillna(email_data_frame['main_message_extra_score'])\n",
    "email_data_frame['subject_line_nwas_score'] = email_data_frame['subject_line_nwas_score'].fillna(email_data_frame['main_message_nwas_score'])\n",
    "\n",
    "# For the 'html_use', 'from', 'day', and 'hour' columns I am replacing any missing values with the most common occurance for each column.\n",
    "# This is sensible because averaging would not make sense in this case, and this would not impact the results. \n",
    "\n",
    "email_data_frame['html_use'] = email_data_frame['html_use'].fillna(email_data_frame['html_use'].value_counts().index[0])\n",
    "email_data_frame['from'] = email_data_frame['from'].fillna(email_data_frame['from'].value_counts().index[0])\n",
    "email_data_frame['day'] = email_data_frame['day'].fillna(email_data_frame['day'].value_counts().index[0])\n",
    "email_data_frame['hour'] = email_data_frame['hour'].fillna(email_data_frame['hour'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIME</th>\n",
       "      <th>Subscribe</th>\n",
       "      <th>Unsubscribe</th>\n",
       "      <th>Mailer</th>\n",
       "      <th>Priority</th>\n",
       "      <th>content</th>\n",
       "      <th>day</th>\n",
       "      <th>email</th>\n",
       "      <th>from</th>\n",
       "      <th>hour</th>\n",
       "      <th>html_use</th>\n",
       "      <th>label</th>\n",
       "      <th>main_message_extra_score</th>\n",
       "      <th>main_message_nwas_score</th>\n",
       "      <th>re</th>\n",
       "      <th>receive_count</th>\n",
       "      <th>subject_line_extra_score</th>\n",
       "      <th>subject_line_nwas_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>multipart/mixed</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TRAIN_00000.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.591313</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.591313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN_00001.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789154</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.687633</td>\n",
       "      <td>0.567793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>multipart/signed</td>\n",
       "      <td>6.0</td>\n",
       "      <td>TRAIN_00002.eml</td>\n",
       "      <td>org</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.377856</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.572255</td>\n",
       "      <td>0.465104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN_00003.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842464</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.817109</td>\n",
       "      <td>0.811058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN_00004.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.619219</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.786136</td>\n",
       "      <td>0.786136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MIME  Subscribe  Unsubscribe  Mailer  Priority           content  day  \\\n",
       "0     1          0            0       0         3   multipart/mixed  5.0   \n",
       "1     1          0            0       1         1        text/plain  1.0   \n",
       "2     1          1            1       0         3  multipart/signed  6.0   \n",
       "3     1          0            0       1         3        text/plain  2.0   \n",
       "4     0          0            0       0         3              none  2.0   \n",
       "\n",
       "             email from  hour  html_use  label  main_message_extra_score  \\\n",
       "0  TRAIN_00000.eml  com   1.0       0.0      0                  0.670096   \n",
       "1  TRAIN_00001.eml  com   0.0       0.0      0                  0.789154   \n",
       "2  TRAIN_00002.eml  org   3.0       0.0      1                  0.463395   \n",
       "3  TRAIN_00003.eml  com   0.0       0.0      0                  0.842464   \n",
       "4  TRAIN_00004.eml  com   5.0       0.0      0                  0.753900   \n",
       "\n",
       "   main_message_nwas_score  re  receive_count  subject_line_extra_score  \\\n",
       "0                 0.591313   0              2                  0.670096   \n",
       "1                 0.674667   0              8                  0.687633   \n",
       "2                 0.377856   1             11                  0.572255   \n",
       "3                 0.821000   0              7                  0.817109   \n",
       "4                 0.619219   0              4                  0.786136   \n",
       "\n",
       "   subject_line_nwas_score  \n",
       "0                 0.591313  \n",
       "1                 0.567793  \n",
       "2                 0.465104  \n",
       "3                 0.811058  \n",
       "4                 0.786136  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None of these columns should now have NaN values:\n",
    "\n",
    "assert not email_data_frame['day'].isnull().values.any()\n",
    "assert not email_data_frame['from'].isnull().values.any()\n",
    "assert not email_data_frame['hour'].isnull().values.any()\n",
    "assert not email_data_frame['html_use'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4319"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows that have the following attributes: unindexible main messages and empty subject-lines.\n",
    "# This ends up being 8 rows of data.\n",
    "\n",
    "email_data_frame = email_data_frame.dropna()\n",
    "len(email_data_frame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining columns should not have NaN values now:\n",
    "\n",
    "assert not email_data_frame['main_message_extra_score'].isnull().values.any()\n",
    "assert not email_data_frame['main_message_nwas_score'].isnull().values.any()\n",
    "assert not email_data_frame['subject_line_extra_score'].isnull().values.any()\n",
    "assert not email_data_frame['subject_line_nwas_score'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype of 'day', 'hour', and 'html_use' columns.\n",
    "\n",
    "email_data_frame['day'] = email_data_frame['day'].astype(int)\n",
    "email_data_frame['hour'] = email_data_frame['hour'].astype(int)\n",
    "email_data_frame['html_use'] = email_data_frame['html_use'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIME</th>\n",
       "      <th>Subscribe</th>\n",
       "      <th>Unsubscribe</th>\n",
       "      <th>Mailer</th>\n",
       "      <th>Priority</th>\n",
       "      <th>content</th>\n",
       "      <th>day</th>\n",
       "      <th>email</th>\n",
       "      <th>from</th>\n",
       "      <th>hour</th>\n",
       "      <th>html_use</th>\n",
       "      <th>label</th>\n",
       "      <th>main_message_extra_score</th>\n",
       "      <th>main_message_nwas_score</th>\n",
       "      <th>re</th>\n",
       "      <th>receive_count</th>\n",
       "      <th>subject_line_extra_score</th>\n",
       "      <th>subject_line_nwas_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>multipart/mixed</td>\n",
       "      <td>5</td>\n",
       "      <td>TRAIN_00000.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.591313</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.591313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN_00001.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789154</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.687633</td>\n",
       "      <td>0.567793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>multipart/signed</td>\n",
       "      <td>6</td>\n",
       "      <td>TRAIN_00002.eml</td>\n",
       "      <td>org</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.377856</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.572255</td>\n",
       "      <td>0.465104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN_00003.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842464</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.817109</td>\n",
       "      <td>0.811058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN_00004.eml</td>\n",
       "      <td>com</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.619219</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.786136</td>\n",
       "      <td>0.786136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MIME  Subscribe  Unsubscribe  Mailer  Priority           content  day  \\\n",
       "0     1          0            0       0         3   multipart/mixed    5   \n",
       "1     1          0            0       1         1        text/plain    1   \n",
       "2     1          1            1       0         3  multipart/signed    6   \n",
       "3     1          0            0       1         3        text/plain    2   \n",
       "4     0          0            0       0         3              none    2   \n",
       "\n",
       "             email from  hour  html_use  label  main_message_extra_score  \\\n",
       "0  TRAIN_00000.eml  com     1         0      0                  0.670096   \n",
       "1  TRAIN_00001.eml  com     0         0      0                  0.789154   \n",
       "2  TRAIN_00002.eml  org     3         0      1                  0.463395   \n",
       "3  TRAIN_00003.eml  com     0         0      0                  0.842464   \n",
       "4  TRAIN_00004.eml  com     5         0      0                  0.753900   \n",
       "\n",
       "   main_message_nwas_score  re  receive_count  subject_line_extra_score  \\\n",
       "0                 0.591313   0              2                  0.670096   \n",
       "1                 0.674667   0              8                  0.687633   \n",
       "2                 0.377856   1             11                  0.572255   \n",
       "3                 0.821000   0              7                  0.817109   \n",
       "4                 0.619219   0              4                  0.786136   \n",
       "\n",
       "   subject_line_nwas_score  \n",
       "0                 0.591313  \n",
       "1                 0.567793  \n",
       "2                 0.465104  \n",
       "3                 0.811058  \n",
       "4                 0.786136  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring the datatypes are all correct for all observations in the dataset:\n",
    "\n",
    "assert email_data_frame['MIME'].apply(type).all() == int\n",
    "assert email_data_frame['Subscribe'].apply(type).all() == int\n",
    "assert email_data_frame['Unsubscribe'].apply(type).all() == int\n",
    "assert email_data_frame['Mailer'].apply(type).all() == int\n",
    "assert email_data_frame['Priority'].apply(type).all() == int\n",
    "assert email_data_frame['content'].apply(type).all() == str\n",
    "assert email_data_frame['day'].apply(type).all() == int\n",
    "assert email_data_frame['email'].apply(type).all() == str\n",
    "assert email_data_frame['from'].apply(type).all() == str\n",
    "assert email_data_frame['hour'].apply(type).all() == int\n",
    "assert email_data_frame['html_use'].apply(type).all() == int\n",
    "assert email_data_frame['label'].apply(type).all() == int\n",
    "assert email_data_frame['main_message_extra_score'].apply(type).all() == float\n",
    "assert email_data_frame['main_message_nwas_score'].apply(type).all() == float\n",
    "assert email_data_frame['re'].apply(type).all() == int\n",
    "assert email_data_frame['receive_count'].apply(type).all() == int\n",
    "assert email_data_frame['subject_line_extra_score'].apply(type).all() == float\n",
    "assert email_data_frame['subject_line_nwas_score'].apply(type).all() == float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['multipart/mixed', 'text/plain', 'multipart/signed', 'none',\n",
       "       'text/html', 'multipart/related', 'multipart/alternative',\n",
       "       '\\n text/html', 'multipart/mixed ', 'multipart/report'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a problem with the ecoding of the content column values.\n",
    "\n",
    "email_data_frame.content.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['multipart/mixed', 'text/plain', 'multipart/signed', 'none',\n",
       "       'text/html', 'multipart/related', 'multipart/alternative',\n",
       "       'multipart/report'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing the encoding problem:\n",
    "\n",
    "email_data_frame.content = email_data_frame.content.replace('\\n text/html', 'text/html')\n",
    "email_data_frame.content = email_data_frame.content.replace('multipart/mixed ', 'multipart/mixed')\n",
    "email_data_frame.content.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Exporting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_data_frame.to_csv(\"/data/thenateandre/email_data_frame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
