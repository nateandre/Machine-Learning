{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual adversarial training implementation\n",
    "\n",
    "Based on the papers: <i>Virtual Adversarial Training: A Regularization Method for Supervised and Semi-supervised Learning</i> and <i>Adversarial Training Methods for Semi-supervised Text Classification</i>. \n",
    "\n",
    "The adversarial loss component is defined as follows: \n",
    "\n",
    "$$ KL[p(y|x; \\theta) || p(y|x+r_{adv}; \\theta)] $$\n",
    "\n",
    "$$ r_{adv} = \\epsilon * g/||g||_2 \\space where \\space g = \\nabla_r KL[p(y|x; \\theta) || p(y|x+r; \\theta)] $$\n",
    "\n",
    "In effect we calculated a vector r_adv which increases the loss with respect to the ground truth label y. We then train the model to effectively view this slight peturbation as being nothing more than noise, and so the peturbed input should still be assigned the same label y by the model. Note: due to standard gradient issues with softmax saturation, we utilize softmax with temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy,KLDivergence\n",
    "from tensorflow.keras.layers import Input,Dense,Reshape,Activation,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from matplotlib import image as plt_image\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_subset(x,y,n=200):\n",
    "    \"\"\" returns n examples for each unique class in the training set\n",
    "    \"\"\"\n",
    "    data_store = defaultdict(list)\n",
    "    for i,y_i in enumerate(y):\n",
    "        data_store[int(y_i)].append(np.expand_dims(x[i],axis=0))\n",
    "        \n",
    "    x_subset = []\n",
    "    y_subset = []\n",
    "    for unique_y_i in data_store:\n",
    "        y_subset += [unique_y_i for _ in range(n)]\n",
    "        x_subset += data_store[unique_y_i][:n]\n",
    "    \n",
    "    x_subset,y_subset = shuffle(np.vstack(x_subset),np.array(y_subset),random_state=1)\n",
    "    return x_subset,y_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1) (1000,) (5139, 28, 28, 1) (5139, 1)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "x_train,y_train,x_test,y_test = mnist[0][0],mnist[0][1],mnist[1][0],mnist[1][1]\n",
    "x_train,y_train = x_train.astype(\"float32\"),y_train.astype(\"int32\")\n",
    "x_test,y_test = x_test.astype(\"float32\"),y_test.astype(\"int32\")\n",
    "x_train,y_train = x_train[y_train <= 4],y_train[y_train <= 4]\n",
    "x_test,y_test = x_test[y_test <= 4],y_test[y_test <= 4]\n",
    "x_train,y_train = np.expand_dims(x_train,axis=-1),np.expand_dims(y_train,axis=-1)\n",
    "x_test,y_test = np.expand_dims(x_test,axis=-1),np.expand_dims(y_test,axis=-1)\n",
    "x,y = get_data_subset(x_train,y_train)\n",
    "print(x.shape,y.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y_true,y_pred,temp):\n",
    "    \"\"\" adversarial loss\n",
    "    \"\"\"\n",
    "    y_pred = Activation('softmax')(y_pred/temp)\n",
    "    loss = KLDivergence()(y_true,y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(optimizer=Adam(lr=0.001)):\n",
    "    \"\"\" model implementation\n",
    "    \"\"\"\n",
    "    x = Input(shape=(28,28))\n",
    "    x_f = Flatten()(x)\n",
    "    h = Dense(128,activation='relu')(x_f)\n",
    "    out = Dense(5,activation=None)(h)\n",
    "    \n",
    "    model = Model(inputs=x,outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(x_train_subset,y_train_subset,adv_x_train_subset,adv_y_train_subset,model,optimizer,kl_w,temp):\n",
    "    \"\"\" training iteration\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_train_pred = model(x_train_subset)\n",
    "        cross_entropy_loss = SparseCategoricalCrossentropy(from_logits=True)(y_train_subset,y_train_pred)\n",
    "        \n",
    "        model_pred = model(adv_x_train_subset)\n",
    "        kl_loss = loss_func(adv_y_train_subset,model_pred,temp)\n",
    "        \n",
    "        loss = (1-kl_w)*cross_entropy_loss + kl_w*kl_loss\n",
    "        \n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adversarial_examples(x_train_subset,model,e=100.0,temp=20.0):\n",
    "    \"\"\" returns adversarial examples utilizing virutal method\n",
    "    \"\"\"\n",
    "    x_train_subset = tf.convert_to_tensor(x_train_subset)\n",
    "    r = tf.random.normal(x_train_subset.shape,mean=0.0,stddev=1.0)\n",
    "    model_true = model(x_train_subset) # output distribution of standard input, used as label of KL divergence\n",
    "    model_true = Activation('softmax')(model_true/temp)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(r)\n",
    "        model_pred = model(x_train_subset+r)\n",
    "        loss = loss_func(model_true,model_pred,temp)\n",
    "    gradients = tape.gradient(loss,r)\n",
    "    \n",
    "    r_adv = e*tf.reshape(tf.math.divide_no_nan(tf.reshape(gradients,(len(x_train_subset),28*28)),tf.norm(gradients,axis=[1,2])),(len(x_train_subset),28,28,1))\n",
    "    adv_x_train_subset = x_train_subset+r_adv\n",
    "    adv_y_train_subset = model_true # adversarial label is output distribution of unaltered input\n",
    "    \n",
    "    return adv_x_train_subset,adv_y_train_subset,np.sum(tf.reshape(r_adv,(len(x_train_subset),28*28)),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9732827398326522\n"
     ]
    }
   ],
   "source": [
    "# average model performance utilizing adversarial regularization\n",
    "final_accuracies = []\n",
    "batch_size=50\n",
    "epochs=100\n",
    "\n",
    "for _ in range(10):\n",
    "    model = get_model()\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    \n",
    "    def train_on_batch(x_train_subset,y_train_subset,adv_x_train_subset,adv_y_train_subset,model,optimizer,kl_w=0.5,temp=20.0):\n",
    "        \"\"\" training iteration wrapper\n",
    "        \"\"\"\n",
    "        loss = run_batch(x_train_subset,y_train_subset,adv_x_train_subset,adv_y_train_subset,model,optimizer,kl_w,temp)\n",
    "        return loss\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        r_zero = 0 # tracks number of \"incorrectly\" generated adversarial examples\n",
    "        r_total = 0\n",
    "        for i in range(0,(len(x)//batch_size)*batch_size,batch_size):\n",
    "            x_train_subset = x[i:i+batch_size]\n",
    "            y_train_subset = y[i:i+batch_size]\n",
    "            adv_x_train_subset,adv_y_train_subset,adv_n = get_adversarial_examples(x_train_subset,model)\n",
    "            r_zero += float(np.sum(adv_n==0))\n",
    "            r_total += len(adv_x_train_subset)\n",
    "            batch_loss = train_on_batch(x_train_subset,y_train_subset,adv_x_train_subset,adv_y_train_subset,model,optimizer)\n",
    "            losses.append(float(batch_loss))\n",
    "            \n",
    "        test_pred = np.argmax(Activation('softmax')(model(x_test).numpy()),axis=-1)\n",
    "        accuracy = recall_score(np.squeeze(y_test),test_pred,average='micro')\n",
    "        accuracies.append(accuracy)\n",
    "        #print(\"Epoch {}; loss:{}, test-acc:{}, adv-perc:{}\".format(epoch_i+1,round(sum(losses)/len(losses),4),accuracy,round(r_zero/r_total,4)))\n",
    "        \n",
    "    final_accuracies.append(max(accuracies))\n",
    "    \n",
    "print(sum(final_accuracies)/len(final_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9617435298696243\n"
     ]
    }
   ],
   "source": [
    "# average model performance of standard model\n",
    "final_accuracies = []\n",
    "batch_size=50\n",
    "epochs=100\n",
    "\n",
    "for _ in range(10):\n",
    "    model = get_model()\n",
    "    model.compile(loss=SparseCategoricalCrossentropy(from_logits=True),optimizer=optimizer)\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for i in range(0,(len(x)//batch_size)*batch_size,batch_size):\n",
    "            x_train_subset = x[i:i+batch_size]\n",
    "            y_train_subset = y[i:i+batch_size]\n",
    "            batch_loss = model.train_on_batch(x_train_subset,y_train_subset)\n",
    "            losses.append(float(batch_loss))\n",
    "            \n",
    "        test_pred = np.argmax(Activation('softmax')(model(x_test).numpy()),axis=-1)\n",
    "        accuracy = recall_score(np.squeeze(y_test),test_pred,average='micro')\n",
    "        accuracies.append(accuracy)\n",
    "        #print(\"Epoch {}; loss:{}, test-acc:{}\".format(epoch_i+1,round(sum(losses)/len(losses),4),accuracy))\n",
    "        \n",
    "    final_accuracies.append(max(accuracies))\n",
    "    \n",
    "print(sum(final_accuracies)/len(final_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of standard model performance on adversarial examples generated with this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_x_test,adv_y_test,_ = get_adversarial_examples(x_test,model)\n",
    "i=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 0.0000000e+00, 2.4069416e-07, 0.0000000e+00,\n",
       "        9.9999976e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Activation('softmax')(model(np.expand_dims(x_test[i],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(x_test[i]),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        2.3731004e-14]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model misclassifies adversarial example as a 2\n",
    "Activation('softmax')(model(np.expand_dims(adv_x_test[i],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(adv_x_test[i]),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
