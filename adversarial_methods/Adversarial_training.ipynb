{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional adversarial training implementation\n",
    "\n",
    "Based on the papers: <i>Explaining and Harnessing Adversarial Examples</i> and <i>Adversarial Training Methods for Semi-supervised Text Classification</i>. \n",
    "\n",
    "The adversarial loss component is defined as follows: \n",
    "\n",
    "$$ -log p(y | x+r_{adv}; \\theta) $$\n",
    "$$ r_{adv} = \\epsilon * g/||g||_2 \\space where \\space g = \\nabla_r -log p(y | x+r; \\theta) $$\n",
    "\n",
    "In effect we calculated a vector r_adv which increases the loss with respect to the ground truth label y. We then train the model to effectively view this slight peturbation as being nothing more than noise, and so the peturbed input should still be assigned the same label y by the model. Note: due to standard gradient issues with softmax saturation, we utilize softmax with temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Input,Dense,Reshape,Activation,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from matplotlib import image as plt_image\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_subset(x,y,n=200):\n",
    "    \"\"\" returns n examples for each unique class in the training set\n",
    "    \"\"\"\n",
    "    data_store = defaultdict(list)\n",
    "    for i,y_i in enumerate(y):\n",
    "        data_store[int(y_i)].append(np.expand_dims(x[i],axis=0))\n",
    "        \n",
    "    x_subset = []\n",
    "    y_subset = []\n",
    "    for unique_y_i in data_store:\n",
    "        y_subset += [unique_y_i for _ in range(n)]\n",
    "        x_subset += data_store[unique_y_i][:n]\n",
    "    \n",
    "    x_subset,y_subset = shuffle(np.vstack(x_subset),np.array(y_subset),random_state=1)\n",
    "    return x_subset,y_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1) (1000,) (5139, 28, 28, 1) (5139, 1)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "x_train,y_train,x_test,y_test = mnist[0][0],mnist[0][1],mnist[1][0],mnist[1][1]\n",
    "x_train,y_train = x_train.astype(\"float32\"),y_train.astype(\"int32\")\n",
    "x_test,y_test = x_test.astype(\"float32\"),y_test.astype(\"int32\")\n",
    "x_train,y_train = x_train[y_train <= 4],y_train[y_train <= 4]\n",
    "x_test,y_test = x_test[y_test <= 4],y_test[y_test <= 4]\n",
    "x_train,y_train = np.expand_dims(x_train,axis=-1),np.expand_dims(y_train,axis=-1)\n",
    "x_test,y_test = np.expand_dims(x_test,axis=-1),np.expand_dims(y_test,axis=-1)\n",
    "x,y = get_data_subset(x_train,y_train)\n",
    "print(x.shape,y.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y_true,y_pred):\n",
    "    \"\"\" standard loss\n",
    "    \"\"\"\n",
    "    loss = SparseCategoricalCrossentropy()(y_true,y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(optimizer=Adam(lr=0.001)):\n",
    "    \"\"\" model implementation\n",
    "    \"\"\"\n",
    "    x = Input(shape=(28,28))\n",
    "    x_f = Flatten()(x)\n",
    "    h = Dense(128,activation='relu')(x_f)\n",
    "    out = Dense(5,activation=None)(h)\n",
    "    \n",
    "    model = Model(inputs=x,outputs=out)\n",
    "    model.compile(loss=SparseCategoricalCrossentropy(from_logits=True),optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adversarial_examples(x_train_subset,y_train_subset,model,e=100.0,temp=20.0):\n",
    "    \"\"\" returns adversarial examples utilizing traditional method\n",
    "    \"\"\"\n",
    "    x_train_subset = tf.convert_to_tensor(x_train_subset)\n",
    "    r = tf.random.normal(x_train_subset.shape,mean=0.0,stddev=1.0)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(r)\n",
    "        model_pred = model(x_train_subset+r)\n",
    "        model_pred = Activation('softmax')(model_pred/temp)\n",
    "        loss = loss_func(y_train_subset,model_pred)\n",
    "    gradients = tape.gradient(loss,r)\n",
    "    \n",
    "    r_adv = e*tf.reshape(tf.math.divide_no_nan(tf.reshape(gradients,(len(x_train_subset),28*28)),tf.norm(gradients,axis=[1,2])),(len(x_train_subset),28,28,1))\n",
    "    adv_x_train_subset = x_train_subset+r_adv\n",
    "    adv_y_train_subset = y_train_subset\n",
    "    \n",
    "    return adv_x_train_subset,adv_y_train_subset,np.sum(tf.reshape(r_adv,(len(x_train_subset),28*28)),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715703444249856\n"
     ]
    }
   ],
   "source": [
    "# average model performance utilizing adversarial regularization\n",
    "final_accuracies = []\n",
    "batch_size=50\n",
    "epochs=30\n",
    "weights = np.ones((batch_size*2)).astype('float32')*0.5 # equal weighting for non-adversarial & adversarial examples\n",
    "\n",
    "for _ in range(10):\n",
    "    model = compile_model()\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        r_zero = 0 # tracks number of \"incorrectly\" generated adversarial examples\n",
    "        r_total = 0\n",
    "        for i in range(0,(len(x)//batch_size)*batch_size,batch_size):\n",
    "            x_train_subset = x[i:i+batch_size]\n",
    "            y_train_subset = y[i:i+batch_size]\n",
    "            adv_x_train_subset,adv_y_train_subset,adv_n = get_adversarial_examples(x_train_subset,y_train_subset,model)\n",
    "            r_zero += float(np.sum(adv_n==0))\n",
    "            r_total += len(adv_x_train_subset)\n",
    "            x_train_subset = np.vstack([x_train_subset,adv_x_train_subset])\n",
    "            y_train_subset = np.concatenate([y_train_subset,adv_y_train_subset])\n",
    "            batch_loss = model.train_on_batch(x_train_subset,y_train_subset,sample_weight=weights)\n",
    "            losses.append(float(batch_loss))\n",
    "            \n",
    "        test_pred = np.argmax(Activation('softmax')(model(x_test).numpy()),axis=-1)\n",
    "        accuracy = recall_score(np.squeeze(y_test),test_pred,average='micro')\n",
    "        accuracies.append(accuracy)\n",
    "        #print(\"Epoch {}; loss:{}, test-acc:{}, adv-perc:{}\".format(epoch_i+1,round(sum(losses)/len(losses),4),accuracy,round(r_zero/r_total,4)))\n",
    "        \n",
    "    final_accuracies.append(max(accuracies))\n",
    "    \n",
    "print(sum(final_accuracies)/len(final_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9630862035415451\n"
     ]
    }
   ],
   "source": [
    "# average model performance of standard model\n",
    "final_accuracies = []\n",
    "batch_size=50\n",
    "epochs=30\n",
    "\n",
    "for _ in range(10):\n",
    "    model = compile_model()\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for i in range(0,(len(x)//batch_size)*batch_size,batch_size):\n",
    "            x_train_subset = x[i:i+batch_size]\n",
    "            y_train_subset = y[i:i+batch_size]\n",
    "            batch_loss = model.train_on_batch(x_train_subset,y_train_subset)\n",
    "            losses.append(float(batch_loss))\n",
    "            \n",
    "        test_pred = np.argmax(Activation('softmax')(model(x_test).numpy()),axis=-1)\n",
    "        accuracy = recall_score(np.squeeze(y_test),test_pred,average='micro')\n",
    "        accuracies.append(accuracy)\n",
    "        #print(\"Epoch {}; loss:{}, test-acc:{}\".format(epoch_i+1,round(sum(losses)/len(losses),4),accuracy))\n",
    "        \n",
    "    final_accuracies.append(max(accuracies))\n",
    "    \n",
    "print(sum(final_accuracies)/len(final_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of standard model performance on adversarial examples generated with this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_x_test,adv_y_test,_ = get_adversarial_examples(x_test,y_test,model)\n",
    "i=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[1.000000e+00, 0.000000e+00, 0.000000e+00, 8.078091e-18,\n",
       "        0.000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Activation('softmax')(model(np.expand_dims(x_test[i],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(x_test[i]),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[1.6189536e-32, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model misclassifies adversarial example as a 3\n",
    "Activation('softmax')(model(np.expand_dims(adv_x_test[i],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(adv_x_test[i]),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
