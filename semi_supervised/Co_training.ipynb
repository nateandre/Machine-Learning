{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-training Implementation\n",
    "\n",
    "Based on papers: <i>Combining Labeled and Unlabeled Data with Co-Training</i> and <i>Co-Training for Cross-Lingual Sentiment Classification</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import regex as re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "universal_embed = hub.load(\"../other/universal-sentence-encoder_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "all_labels = []\n",
    "with open(\"../data/sentiment/amazon_electronics_reviews/reviews.txt\") as infile:\n",
    "    lines = infile.readlines()\n",
    "    for line in lines:\n",
    "        all_labels.append(int(line[0]))\n",
    "        all_text.append(line[2:])\n",
    "        \n",
    "all_text = all_text[:10000]\n",
    "all_labels = all_labels[:10000]\n",
    "\n",
    "all_text_nc = [] # noun chunks\n",
    "all_text_no_nc = [] # no noun chunks\n",
    "for text in all_text:\n",
    "    doc = nlp(text)\n",
    "    noun_chunks = [tok.text for tok in doc.noun_chunks]\n",
    "    text_nc = \" \".join(noun_chunks).lower()\n",
    "    all_text_nc.append(text_nc)\n",
    "    text_no_nc = text\n",
    "    for nc in noun_chunks:\n",
    "        text_no_nc = re.sub(re.escape(nc),\"\",text_no_nc)\n",
    "    text_no_nc = re.sub(\"\\\\s+\",\" \",text_no_nc)\n",
    "    all_text_no_nc.append(text_no_nc.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = universal_embed(all_text_nc).numpy()\n",
    "data_y = np.array(all_labels)\n",
    "data_x_o = universal_embed(all_text_no_nc).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 512) (5000, 512) (1000, 512)\n",
      "(100, 512) (5000, 512) (1000, 512)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "data_x,data_x_o,data_y = shuffle(data_x,data_x_o,data_y)\n",
    "x_lab,x_lab_o,y_lab = data_x[:100],data_x_o[:100],data_y[:100]\n",
    "x_unl,x_unl_o = data_x[100:5100],data_x_o[100:5100]\n",
    "x_test,x_test_o,y_test = data_x[5100:6100],data_x_o[5100:6100],data_y[5100:6100]\n",
    "\n",
    "print(x_lab.shape,x_unl.shape,x_test.shape)\n",
    "print(x_lab_o.shape,x_unl_o.shape,x_test_o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754 0.659\n",
      "0.775 0.691\n",
      "0.784 0.69\n",
      "0.793 0.69\n",
      "0.788 0.697\n"
     ]
    }
   ],
   "source": [
    "n_iter_total=5\n",
    "n_add=10\n",
    "\n",
    "# initializing U and U'\n",
    "u_ind = [i for i in range(len(x_unl))] # U for both models\n",
    "np.random.seed(10)\n",
    "u_p_ind_o = list(np.random.choice(u_ind,400,replace=False)) # U'\n",
    "u_p_ind = u_p_ind_o # U'\n",
    "u_ind = [i for i in u_ind if i not in u_p_ind_o]\n",
    "\n",
    "lx,y = x_lab,y_lab\n",
    "lx_o,y_o = x_lab_o,y_lab\n",
    "\n",
    "for n_iter in range(1,n_iter_total+1):\n",
    "    # adding to U'\n",
    "    np.random.seed(10)\n",
    "    u_p_ind_o_addition = list(np.random.choice(u_ind,100,replace=False))\n",
    "    u_ind = [i for i in u_ind if i not in u_p_ind_o_addition]\n",
    "    u_p_ind_o = u_p_ind_o+u_p_ind_o_addition\n",
    "    u_p_ind = u_p_ind+u_p_ind_o_addition\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr_o = LogisticRegression()\n",
    "    lr.fit(lx,y)\n",
    "    lr_o.fit(lx_o,y_o)\n",
    "    \n",
    "    print(lr_o.score(x_test_o,y_test),lr.score(x_test,y_test))\n",
    "    \n",
    "    ind_o = [i for i in range(len(u_p_ind_o))]\n",
    "    ind = ind_o\n",
    "    \n",
    "    lr_prob = lr.predict_proba(x_unl[u_p_ind])[:,1] # prob of class 1\n",
    "    lr_prob_o = lr_o.predict_proba(x_unl[u_p_ind_o])[:,1]\n",
    "\n",
    "    rank_i,lr_prob_sorted = zip(*sorted(zip(ind,list(lr_prob)),key=lambda x:x[1]))\n",
    "    rank_i_o,lr_prob_o_sorted = zip(*sorted(zip(ind_o,list(lr_prob_o)),key=lambda x:x[1]))    \n",
    "    \n",
    "    # adding the new labels for L for both models\n",
    "    lx_neg,y_neg = x_unl[np.array(u_p_ind_o)[list(rank_i_o[:n_add])]],np.zeros((n_add))\n",
    "    lx_pos,y_pos = x_unl[np.array(u_p_ind_o)[list(rank_i_o[-n_add:])]],np.ones((n_add))\n",
    "    lx,y = np.vstack([lx,lx_neg,lx_pos]),np.concatenate([y,y_neg,y_pos])\n",
    "    \n",
    "    lx_o_neg = x_unl[np.array(u_p_ind)[list(rank_i[:n_add])]]\n",
    "    lx_o_pos = x_unl[np.array(u_p_ind)[list(rank_i[-n_add:])]]\n",
    "    lx_o,y_o = np.vstack([lx_o,lx_o_neg,lx_o_pos]),np.concatenate([y_o,y_neg,y_pos])\n",
    "    \n",
    "    # updating U' for both models\n",
    "    lx_o_indices = list(np.array(u_p_ind_o)[list(rank_i_o[:n_add])])+list(np.array(u_p_ind_o)[list(rank_i_o[-n_add:])])\n",
    "    u_p_ind_o = [i for i in u_p_ind_o if i not in lx_o_indices]\n",
    "    lx_indices = list(np.array(u_p_ind)[list(rank_i[:n_add])])+list(np.array(u_p_ind)[list(rank_i[-n_add:])])\n",
    "    u_p_ind = [i for i in u_p_ind if i not in lx_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
