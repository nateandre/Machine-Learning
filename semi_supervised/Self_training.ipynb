{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-training Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input,Dense,Dropout,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "nnlm_embed = hub.load(\"../other/nnlm-en-dim128_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "all_labels = []\n",
    "with open(\"../data/sentiment/amazon_electronics_reviews/reviews.txt\") as infile:\n",
    "    lines = infile.readlines()\n",
    "    for line in lines:\n",
    "        all_labels.append(int(line[0]))\n",
    "        all_text.append(line[2:])\n",
    "        \n",
    "all_text = all_text[:20000]\n",
    "all_labels = all_labels[:20000]\n",
    "\n",
    "data_x = nnlm_embed(all_text)\n",
    "data_y = np.array(all_labels)\n",
    "data = np.hstack([data_x,np.expand_dims(data_y,-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128) (5000, 128) (1000, 128)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "data = shuffle(data)\n",
    "labeled_data = data[:100]\n",
    "x_lab,y_lab = labeled_data[:,:-1],labeled_data[:,-1]\n",
    "unlabeled_data = data[100:5100]\n",
    "x_unl = unlabeled_data[:,:-1]\n",
    "test_data = data[5100:6100]\n",
    "x_test,y_test = test_data[:,:-1],test_data[:,-1]\n",
    "print(x_lab.shape,x_unl.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim=128):\n",
    "    \"\"\" Model instantiation\n",
    "    \"\"\"\n",
    "    x = Input(shape=(input_dim))\n",
    "    h = Dense(50,activation=\"relu\")(x)\n",
    "    o = Dense(1,activation=\"sigmoid\")(h)\n",
    "    \n",
    "    model = Model(inputs=x,outputs=o)\n",
    "    model.compile(loss=BinaryCrossentropy(),optimizer=Adam(lr=0.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train,y_train,sample_weights,batch_size=25,epochs=50):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    model=get_model()\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        x_train,y_train = shuffle(x_train,y_train)\n",
    "        for i in range(0,len(x_train),batch_size):\n",
    "            x_train_subset = x_train[i:i+batch_size]\n",
    "            y_train_subset = y_train[i:i+batch_size]\n",
    "            sample_weight = sample_weights[i:i+batch_size]\n",
    "            batch_loss = model.train_on_batch(x_train_subset,y_train_subset,sample_weight=sample_weight)\n",
    "            losses.append(float(batch_loss))\n",
    "\n",
    "    test_pred = model(x_test).numpy()\n",
    "    test_pred[test_pred>=0.5]=1 ; test_pred[test_pred<0.5]=0\n",
    "    test_acc = balanced_accuracy_score(y_test,test_pred)\n",
    "    \n",
    "    return model,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.686\n",
      "New labels: 57\n",
      "Acc: 0.707\n",
      "New labels: 93\n",
      "Acc: 0.706\n",
      "New labels: 100\n",
      "Acc: 0.703\n",
      "New labels: 251\n",
      "Acc: 0.703\n",
      "New labels: 275\n"
     ]
    }
   ],
   "source": [
    "n_iter_total=5\n",
    "epochs=[10]*5\n",
    "x_train,y_train = x_lab,y_lab\n",
    "x_unl_all = x_unl\n",
    "sample_weights = np.ones((len(x_train))) # if wanting to weigh additional datapoints\n",
    "\n",
    "for n_iter in range(1,n_iter_total+1):\n",
    "    model,test_acc = train_model(x_train,y_train,sample_weights,epochs=epochs[n_iter-1])\n",
    "    print(\"Acc:\",round(test_acc,3))\n",
    "    \n",
    "    if len(x_unl_all)<=1:\n",
    "        break\n",
    "    \n",
    "    unl_predictions = model(x_unl_all).numpy()[:,0]\n",
    "    unl_indices = np.array(range(len(unl_predictions)))\n",
    "    neg_pred_indices = unl_indices[unl_predictions<=0.001]\n",
    "    pos_pred_indices = unl_indices[unl_predictions>=0.999]\n",
    "    print(\"New labels:\",len(neg_pred_indices)+len(pos_pred_indices))\n",
    "    \n",
    "    x_train,y_train = np.vstack([x_train,x_unl_all[neg_pred_indices]]),np.concatenate([y_train,np.zeros((len(neg_pred_indices)))])\n",
    "    x_train,y_train = np.vstack([x_train,x_unl_all[pos_pred_indices]]),np.concatenate([y_train,np.ones((len(pos_pred_indices)))])\n",
    "    sample_weights = np.concatenate([sample_weights,np.ones((len(neg_pred_indices)+len(pos_pred_indices)))/n_iter])\n",
    "    \n",
    "    new_unl_indices = [i for i in unl_indices if i not in neg_pred_indices and i not in pos_pred_indices]\n",
    "    x_unl_all = x_unl_all[new_unl_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
